{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from model import MLPNeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('home-data-for-ml-course/train.csv')\n",
    "test_df = pd.read_csv('home-data-for-ml-course/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 is numerical, 1 is categorical\n",
    "columns_dtypes = {\n",
    "    'MSSubClass': 1,\n",
    "    'MSZoning': 1,\n",
    "    'LotFrontage': 0,\n",
    "    'LotArea': 0,\n",
    "    'Street': 1,\n",
    "    'Alley': 1,\n",
    "    'LotShape': 1,\n",
    "    'LandContour': 1,\n",
    "    'Utilities': 1,\n",
    "    'LotConfig': 1,\n",
    "    'LandSlope': 1,\n",
    "    'Neighborhood': 1,\n",
    "    'Condition1': 1,\n",
    "    'Condition2': 1,\n",
    "    'BldgType': 1,\n",
    "    'HouseStyle': 1,\n",
    "    'OverallQual': 1,\n",
    "    'OverallCond': 1,\n",
    "    'YearBuilt': 0,\n",
    "    'YearRemodAdd': 0,\n",
    "    'RoofStyle': 1,\n",
    "    'RoofMatl': 1,\n",
    "    'Exterior1st': 1,\n",
    "    'Exterior2nd': 1,\n",
    "    'MasVnrType': 1,\n",
    "    'MasVnrArea': 0,\n",
    "    'ExterQual': 1,\n",
    "    'ExterCond': 1,\n",
    "    'Foundation': 1,\n",
    "    'BsmtQual': 1,\n",
    "    'BsmtCond': 1,\n",
    "    'BsmtExposure': 1,\n",
    "    'BsmtFinType1': 1,\n",
    "    'BsmtFinSF1': 0,\n",
    "    'BsmtFinType2': 1,\n",
    "    'BsmtFinSF2': 0,\n",
    "    'BsmtUnfSF': 0,\n",
    "    'TotalBsmtSF': 0,\n",
    "    'Heating': 1,\n",
    "    'HeatingQC': 1,\n",
    "    'CentralAir': 1,\n",
    "    'Electrical': 1,\n",
    "    '1stFlrSF': 0,\n",
    "    '2ndFlrSF': 0,\n",
    "    'LowQualFinSF': 0,\n",
    "    'GrLivArea': 0,\n",
    "    'BsmtFullBath': 0,\n",
    "    'BsmtHalfBath': 0,\n",
    "    'FullBath': 0,\n",
    "    'HalfBath': 0,\n",
    "    'BedroomAbvGr': 0,\n",
    "    'KitchenAbvGr': 0,\n",
    "    'KitchenQual': 1,\n",
    "    'TotRmsAbvGrd': 0,\n",
    "    'Functional': 1,\n",
    "    'Fireplaces': 0,\n",
    "    'FireplaceQu': 1,\n",
    "    'GarageType': 1,\n",
    "    'GarageYrBlt': 0,\n",
    "    'GarageFinish': 1,\n",
    "    'GarageCars': 0,\n",
    "    'GarageArea': 0,\n",
    "    'GarageQual': 1,\n",
    "    'GarageCond': 1,\n",
    "    'PavedDrive': 1,\n",
    "    'WoodDeckSF': 0,\n",
    "    'OpenPorchSF': 0,\n",
    "    'EnclosedPorch': 0,\n",
    "    '3SsnPorch': 0,\n",
    "    'ScreenPorch': 0,\n",
    "    'PoolArea': 0,\n",
    "    'PoolQC': 1,\n",
    "    'Fence': 1,\n",
    "    'MiscFeature': 1,\n",
    "    'MiscVal': 0,\n",
    "    'MoSold': 0,\n",
    "    'YrSold': 0,\n",
    "    'SaleType': 1,\n",
    "    'SaleCondition': 1,\n",
    "    'SalePrice': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nomalization(data: pd.DataFrame, label_col: str):\n",
    "    data_to_normalize = data.drop(columns=[label_col])\n",
    "    features_max = data_to_normalize.max()\n",
    "    features_min = data_to_normalize.min()\n",
    "    normalized_data = 2 * (data_to_normalize - features_min) / (features_max - features_min) - 1\n",
    "    normalized_data[label_col] = data[label_col]\n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data: pd.DataFrame, columns_dtype: dict, label_col: str):\n",
    "    imputer = KNNImputer(n_neighbors=int(np.sqrt(len(data))))\n",
    "    for col in data.columns:\n",
    "        if columns_dtype[col] == 1: # categorical\n",
    "            data[col] = data[col].fillna('unknown')\n",
    "        else: # numerical\n",
    "            imputed_values = imputer.fit_transform(data[[col]])\n",
    "            data[col] = imputed_values.flatten()\n",
    "                \n",
    "    categorical_cols = [col for col in data.columns if columns_dtype[col] == 1]\n",
    "    numerical_cols = [col for col in data.columns if columns_dtype[col] == 0]\n",
    "                \n",
    "    encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False, drop='first')\n",
    "    encoded_categorical_data = encoder.fit_transform(data[categorical_cols])\n",
    "    encoded_feature_names = encoder.get_feature_names_out(categorical_cols)\n",
    "    \n",
    "    for feature in encoded_feature_names:\n",
    "        columns_dtype[feature] = 1\n",
    "    \n",
    "    categorical_df = pd.DataFrame(encoded_categorical_data, columns=encoded_feature_names, index=data.index)\n",
    "    \n",
    "    normalized_numerical_data = nomalization(data[numerical_cols], label_col)\n",
    "    \n",
    "    df = pd.concat([categorical_df, normalized_numerical_data], axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_np(df: pd.DataFrame, label_col: str):\n",
    "\tfeatures_data = df.drop(columns=[label_col]).to_numpy()\n",
    "\tlabel_data = df[label_col].to_numpy()\n",
    "\treturn features_data, label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold(features: np.ndarray, labels: np.ndarray, k: int):\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    return kf.split(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_transformer = FunctionTransformer(func=preprocess_data, kw_args={'columns_dtype': columns_dtypes, 'label_col': 'SalePrice'})\n",
    "np_transformer = FunctionTransformer(func=df_to_np, kw_args={'label_col': 'SalePrice'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessed\n",
      "Dataframe turned into numpy arrays\n",
      "Training features shape:  (1460, 288)\n",
      "Training labels shape:  (1460,)\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocess', preprocess_transformer),\n",
    "    ('df_to_np', np_transformer)\n",
    "])\n",
    "\n",
    "train_features, train_labels = pipeline.fit_transform(train_df.drop(columns=['Id']))\n",
    "\n",
    "print('Data preprocessed')\n",
    "print('Dataframe turned into numpy arrays')\n",
    "print('Training features shape: ', train_features.shape)\n",
    "print('Training labels shape: ', train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold_index = []\n",
    "for train_index, test_index in k_fold(train_features, train_labels, k=7):\n",
    "    k_fold_index.append([train_index, test_index])\n",
    "\n",
    "params = {\n",
    "    'alphas': [0.6, 0.7, 0.8, 0.9],\n",
    "    'lambdas': [0, 0.1, 0.2],\n",
    "    'epsilons': [math.pow(math.e, -6), math.pow(math.e, -5)],\n",
    "    'hidden_sizes': [5, 10],\n",
    "    'neurons_per_layer': [10, 20],\n",
    "    'early_stopping_threshold': 60000,\n",
    "    'early_stopping_folds': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No parameter file found. You will need to run grid_search before fitting the model.\n",
      "Or load parameters manually using load_parameters(filename).\n",
      "Model: MLP - Multi-Layer Perceptron\n",
      "Type: Regression\n",
      "Purpose: Housing Prices Prediction\n",
      "\n",
      "Architecture:\n",
      "  Input size: 288\n",
      "  Output size: 1\n",
      "\n",
      "Note: No parameters loaded. Run grid_search or load_parameters first.\n",
      "\n",
      "Status: Model needs initialization before training/prediction\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neural_network = MLPNeuralNetwork(len(train_features[0]), 1)\n",
    "neural_network.get_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with alpha=0.6, lambda=0, epsilon=0.0009118819655545166, layer=1, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170270.23230098857\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149611.15695853136\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 144544.36928725263\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 139259.0131228234\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 121997.66541064327\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 100106.5953145125\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 91433.48965908716\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 83818.69309803071\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 70651.32075706692\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 62669.11440256013\n",
      "Mean MAE: 113436.16503114966\n",
      "\n",
      "Training with alpha=0.6, lambda=0, epsilon=0.0009118819655545166, layer=1, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159926.3370908217\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 128850.04273774505\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 113293.07698423776\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 99744.79115495425\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 74544.86800447816\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 54139.72284566098\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 60482.64226811713\n",
      "Processing fold 8...\n",
      "Converged at epoch 47\n",
      "MAE for fold 8: 54395.39796029302\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 42094.33281529639\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 30985.13865130775\n",
      "Mean MAE: 81845.63505129123\n",
      "\n",
      "Training with alpha=0.6, lambda=0, epsilon=0.0009118819655545166, layer=1, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138904.50239615815\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89238.1447574476\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 59790.27570811544\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 60428.98434177881\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 36651.09713343412\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 24142.09934149759\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 23776.347740669346\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 18769.03460194703\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 16623.036692771595\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 19694.11525127409\n",
      "Mean MAE: 48801.763796509375\n",
      "\n",
      "Training with alpha=0.6, lambda=0, epsilon=0.0009118819655545166, layer=3, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170268.65229893124\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149609.5769564737\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 144542.78928519486\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 139257.4331207654\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 121996.10705244924\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 100105.0153124545\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 91432.14773953117\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 83817.4161100661\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 70650.19527614891\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 62668.17162071693\n",
      "Mean MAE: 113434.7504772732\n",
      "\n",
      "Training with alpha=0.6, lambda=0, epsilon=0.0009118819655545166, layer=3, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159770.04820478585\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 128695.89479535287\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 113138.92904184519\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 99614.19359264978\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 74433.5389349724\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 54099.04491641825\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 60496.15216129878\n",
      "Processing fold 8...\n",
      "Converged at epoch 41\n",
      "MAE for fold 8: 54395.513637770375\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 54812.33998469375\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 52586.40548597945\n",
      "Mean MAE: 85204.20607557669\n",
      "\n",
      "Training with alpha=0.6, lambda=0, epsilon=0.0009118819655545166, layer=3, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138891.32285902614\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89226.79571158394\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 59783.86898867623\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 60438.6918807543\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 53750.36186868667\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 52962.59235544244\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 64149.00049967007\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 55420.63467129432\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 55659.240175729996\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 52669.864404164306\n",
      "Mean MAE: 68295.23734150283\n",
      "\n",
      "Training with alpha=0.6, lambda=0, epsilon=0.0009118819655545166, layer=5, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170268.42518153114\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149609.34983907358\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 144542.56216779482\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 139257.20600336534\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 121995.8830462464\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 100104.78819505441\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 91431.95484530093\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 83817.23254942766\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 70650.03349389133\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 62668.03783923469\n",
      "Mean MAE: 113434.54731609202\n",
      "\n",
      "Training with alpha=0.6, lambda=0, epsilon=0.0009118819655545166, layer=5, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159768.6252922936\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 128694.49137481258\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 113137.52562130493\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 99613.00458358097\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 74432.5253534711\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 54098.67456933123\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 60496.49956386653\n",
      "Processing fold 8...\n",
      "Converged at epoch 42\n",
      "MAE for fold 8: 54395.737039825595\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 54803.282823483954\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 52566.405875678975\n",
      "Mean MAE: 85200.67720976494\n",
      "\n",
      "Training with alpha=0.6, lambda=0, epsilon=0.0009118819655545166, layer=5, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138889.2695367337\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89225.02757294322\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 59782.87084589516\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 60435.58403640677\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 53733.31965284649\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 52995.00718195112\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 64130.009223137844\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 55423.07564788583\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 55646.29049260442\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 52679.08820042762\n",
      "Mean MAE: 68293.9542390832\n",
      "\n",
      "Training with alpha=0.6, lambda=0, epsilon=0.0009118819655545166, layer=10, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170270.00301173315\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149610.9276692757\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 144544.13999799686\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 139258.78383356737\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 121997.43926233609\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 100106.36602525646\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 91433.29492026707\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 83818.50778205671\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 70651.15742773388\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 62668.97620081685\n",
      "Mean MAE: 113435.95961310403\n",
      "\n",
      "Training with alpha=0.6, lambda=0, epsilon=0.0009118819655545166, layer=10, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159768.8426106426\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 128694.70571619783\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 113137.73996269018\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 99613.1861783657\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 74432.68015558265\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 54098.73113164122\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 60494.36913607965\n",
      "Processing fold 8...\n",
      "Converged at epoch 42\n",
      "MAE for fold 8: 54395.869495625535\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 54806.70264309616\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 52573.49185672279\n",
      "Mean MAE: 85201.63188866441\n",
      "\n",
      "Training with alpha=0.6, lambda=0, epsilon=0.0009118819655545166, layer=10, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138888.7118314319\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89224.54732671105\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 59782.59973915123\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 60425.02871866475\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 53742.55130929164\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 52996.508625482675\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 64112.363940635\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 55437.419623511945\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 55677.01247807805\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 52690.20592488181\n",
      "Mean MAE: 68297.69495178401\n",
      "\n",
      "Training with alpha=0.6, lambda=0, epsilon=0.0024787521766663594, layer=1, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170279.51773036507\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149620.44238790788\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 144553.6547166292\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 139268.29855219988\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 122006.8236423571\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 100115.880743889\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 91441.37591417407\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 83826.19776012938\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 70657.93503552677\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 62674.71109971848\n",
      "Mean MAE: 113444.48375828967\n",
      "\n",
      "Training with alpha=0.6, lambda=0, epsilon=0.0024787521766663594, layer=1, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159883.55723208256\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 128807.84890446799\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 113250.88315096051\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 99709.04360176105\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 74514.39468044462\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 54128.588361879476\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 60484.001980598965\n",
      "Processing fold 8...\n",
      "Converged at epoch 46\n",
      "MAE for fold 8: 54396.36892693746\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 37148.714135122704\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 30884.32556554092\n",
      "Mean MAE: 81320.77265397963\n",
      "\n",
      "Training with alpha=0.6, lambda=0, epsilon=0.0024787521766663594, layer=1, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138931.57242692786\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89261.45506172156\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 59803.434750850734\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 60437.14620460521\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 34792.72002622018\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 25818.980584748453\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 22680.332174883817\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 18521.9597500913\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 18361.213327306443\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 18566.893011332286\n",
      "Mean MAE: 48717.57073186878\n",
      "\n",
      "Training with alpha=0.6, lambda=0, epsilon=0.0024787521766663594, layer=3, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170270.62015876352\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149611.54481630604\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 144544.7571450272\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 139259.40098059777\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 121998.04795529754\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 100106.98317228685\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 91433.81907253945\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 83819.00657212232\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 70651.59703931714\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 62669.34817984883\n",
      "Mean MAE: 113436.51250921066\n",
      "\n",
      "Training with alpha=0.6, lambda=0, epsilon=0.0024787521766663594, layer=3, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159769.78322647628\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 128695.63344688315\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 113138.66769337552\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 99613.97217241854\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 74433.35018329983\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 54098.975949460975\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 60495.12277565723\n",
      "Processing fold 8...\n",
      "Converged at epoch 41\n",
      "MAE for fold 8: 54396.22240608218\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 54801.84523636644\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 52570.107180166226\n",
      "Mean MAE: 85201.36802701863\n",
      "\n",
      "Training with alpha=0.6, lambda=0, epsilon=0.0024787521766663594, layer=3, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138890.80106290051\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89226.34638714245\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 59783.61533778183\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 60437.34004751014\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 53734.84552696356\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 52942.79545768617\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 64116.32900007513\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 55423.18444458393\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 55668.15363431385\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 52698.46663636484\n",
      "Mean MAE: 68292.18775353224\n",
      "\n",
      "Training with alpha=0.6, lambda=0, epsilon=0.0024787521766663594, layer=5, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170269.1943459201\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149610.11900346258\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 144543.33133218376\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 139257.9751677543\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 121996.64167413687\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 100105.55735944337\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 91432.60810820664\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 83817.85420283795\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 70650.58139181224\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 62668.49090866928\n",
      "Mean MAE: 113435.23534944272\n",
      "\n",
      "Training with alpha=0.6, lambda=0, epsilon=0.0024787521766663594, layer=5, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159768.26311456063\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 128694.13415841835\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 113137.16840491066\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 99612.70194191358\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 74432.26736385298\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 54098.580303893854\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 60496.11237542997\n",
      "Processing fold 8...\n",
      "Converged at epoch 41\n",
      "MAE for fold 8: 54395.41582460735\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 54834.27349885587\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 52569.79168513275\n",
      "Mean MAE: 85203.8708671576\n",
      "\n",
      "Training with alpha=0.6, lambda=0, epsilon=0.0024787521766663594, layer=5, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138889.71840141923\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89225.41409531132\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 59783.089044006236\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 60437.1700583839\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 53736.97690770035\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 52980.28895070898\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 64142.829656517366\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 55400.71822173776\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 55672.32751278303\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 52709.32209530645\n",
      "Mean MAE: 68297.78549438747\n",
      "\n",
      "Training with alpha=0.6, lambda=0, epsilon=0.0024787521766663594, layer=10, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170269.47310438316\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149610.3977619257\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 144543.61009064683\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 139258.25392621738\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 121996.9166139909\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 100105.83611790647\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 91432.84486196982\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 83818.07950077383\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 70650.77995948457\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 62668.65680460588\n",
      "Mean MAE: 113435.48487419046\n",
      "\n",
      "Training with alpha=0.6, lambda=0, epsilon=0.0024787521766663594, layer=10, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159770.18512245704\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 128696.02983743948\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 113139.0640839318\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 99614.30800330652\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 74433.63646536824\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 54099.08055252442\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 60496.349991111136\n",
      "Processing fold 8...\n",
      "Converged at epoch 41\n",
      "MAE for fold 8: 54396.123879834544\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 54822.042346332004\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 52571.20497118143\n",
      "Mean MAE: 85203.80252534866\n",
      "\n",
      "Training with alpha=0.6, lambda=0, epsilon=0.0024787521766663594, layer=10, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138887.5008889635\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89223.50457069656\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 59782.01108656238\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 60429.468595986065\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 53739.47101895696\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 52959.08746440532\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 64155.15824778551\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 55401.416702397866\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 55687.56571067783\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 52699.19478458981\n",
      "Mean MAE: 68296.4379071022\n",
      "\n",
      "Training with alpha=0.6, lambda=0, epsilon=0.006737946999085469, layer=1, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 172348.7012539269\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 151689.625911468\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 146622.83824019812\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 141337.48207576884\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 124047.66218615114\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 102185.064267458\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 93224.50920732366\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 85551.12767391028\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 72159.79255662263\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 63951.46149579141\n",
      "Mean MAE: 115311.82648686189\n",
      "\n",
      "Training with alpha=0.6, lambda=0, epsilon=0.006737946999085469, layer=1, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159775.18315347144\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 128700.95940227577\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 113143.99364876826\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 99618.48444018146\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 74437.19670663911\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 54100.38140991205\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 60492.70634430144\n",
      "Processing fold 8...\n",
      "Converged at epoch 42\n",
      "MAE for fold 8: 54396.3374705752\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 38747.52098053301\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 29736.103840628664\n",
      "Mean MAE: 81314.88673972864\n",
      "\n",
      "Training with alpha=0.6, lambda=0, epsilon=0.006737946999085469, layer=1, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138901.35147175202\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89235.43146143112\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 59788.74400875128\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 60430.07994107667\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 36546.83941989131\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 23343.14570811103\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 22802.157836264763\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 17758.299191490907\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 17491.617288620906\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 18660.691926532923\n",
      "Mean MAE: 48495.8358253923\n",
      "\n",
      "Training with alpha=0.6, lambda=0, epsilon=0.006737946999085469, layer=3, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170267.43515321641\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149608.3598107588\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 144541.57213947995\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 139256.2159750505\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 121994.90657996325\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 100103.79816673954\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 91431.11399933492\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 83816.43238955674\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 70649.32826824236\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 62667.454671871135\n",
      "Mean MAE: 113433.66171542136\n",
      "\n",
      "Training with alpha=0.6, lambda=0, epsilon=0.006737946999085469, layer=3, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159769.6638760403\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 128695.5157313847\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 113138.54997787702\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 99613.87244123228\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 74433.2651665509\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 54098.94488564887\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 60494.07942569904\n",
      "Processing fold 8...\n",
      "Converged at epoch 42\n",
      "MAE for fold 8: 54395.67340057884\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 54837.33022995127\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 52576.23417291364\n",
      "Mean MAE: 85205.31293078768\n",
      "\n",
      "Training with alpha=0.6, lambda=0, epsilon=0.006737946999085469, layer=3, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138889.92372793058\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89225.59090425166\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 59783.188855504784\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 60434.62714450617\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 53738.576459576056\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 52956.730642836694\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 64088.670481561225\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 55402.00875215398\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 55717.28648864959\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 52686.18495617488\n",
      "Mean MAE: 68292.27884131458\n",
      "\n",
      "Training with alpha=0.6, lambda=0, epsilon=0.006737946999085469, layer=5, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170268.9424760188\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149609.8671335613\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 144543.07946228248\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 139257.72329785302\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 121996.39325450825\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 100105.3054895421\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 91432.39419130419\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 83817.65063675333\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 70650.40197763598\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 62668.3425469466\n",
      "Mean MAE: 113435.0100466406\n",
      "\n",
      "Training with alpha=0.6, lambda=0, epsilon=0.006737946999085469, layer=5, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159771.61944618725\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 128697.44451289943\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 113140.47875939171\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 99615.50654779338\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 74434.65817542266\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 54099.45386965969\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 60494.73574089044\n",
      "Processing fold 8...\n",
      "Converged at epoch 41\n",
      "MAE for fold 8: 54396.081924970444\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 54822.220654504425\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 52574.550382323905\n",
      "Mean MAE: 85204.67500140434\n",
      "\n",
      "Training with alpha=0.6, lambda=0, epsilon=0.006737946999085469, layer=5, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138890.9950542382\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89226.51343523871\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 59783.7096391265\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 60438.24981815881\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 53744.98179324821\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 52958.72720784711\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 64131.83128258295\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 55415.821658688124\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 55684.17692144762\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 52709.68741211292\n",
      "Mean MAE: 68298.46942226891\n",
      "\n",
      "Training with alpha=0.6, lambda=0, epsilon=0.006737946999085469, layer=10, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170269.54847637023\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149610.47313391272\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 144543.68546263388\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 139258.32929820442\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 121996.99095348493\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 100105.91148989351\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 91432.90887653414\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 83818.14041785923\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 70650.83364911916\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 62668.70223429669\n",
      "Mean MAE: 113435.55239923086\n",
      "\n",
      "Training with alpha=0.6, lambda=0, epsilon=0.006737946999085469, layer=10, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159769.95652675108\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 128695.80437318164\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 113138.838619674\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 99614.11698497702\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 74433.47363007099\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 54099.021055011974\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 60493.418486589755\n",
      "Processing fold 8...\n",
      "Converged at epoch 42\n",
      "MAE for fold 8: 54395.568888289024\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 54845.406539852615\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 52593.47924137844\n",
      "Mean MAE: 85207.90843457766\n",
      "\n",
      "Training with alpha=0.6, lambda=0, epsilon=0.006737946999085469, layer=10, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138890.24668416142\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89225.86900545044\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 59783.34584811697\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 60434.37906550704\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 53743.08908094931\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 52943.59220560369\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 64143.98547956016\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 55404.6349178995\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 55698.22254804219\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 52706.32532885858\n",
      "Mean MAE: 68297.36901641493\n",
      "\n",
      "Training with alpha=0.6, lambda=0.1, epsilon=0.0009118819655545166, layer=1, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170472.18948896197\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149813.11414650452\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 144746.3264752266\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 139460.9703108194\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 122196.85606179641\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 103149.43258770027\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 101802.9796788056\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 104449.60590563959\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 101173.70434393384\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 102723.26168771969\n",
      "Mean MAE: 123998.84406871078\n",
      "\n",
      "Training with alpha=0.6, lambda=0.1, epsilon=0.0009118819655545166, layer=1, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 160385.97378654272\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 129303.38304037177\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 113746.41728686918\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 100222.24915745405\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 73853.18378583071\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 53921.20622136962\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 54555.452376874964\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 53471.164292785405\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 51866.28149016931\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 50518.386451314356\n",
      "Mean MAE: 84184.36978895823\n",
      "\n",
      "Training with alpha=0.6, lambda=0.1, epsilon=0.0009118819655545166, layer=1, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138926.88406996254\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89257.41786543961\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 57686.29587065741\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 44332.48259979571\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 29287.063767149866\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 26737.9974174246\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 22576.36457412862\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 20834.35276930644\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 20713.721179770426\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 19971.323567328196\n",
      "Mean MAE: 47032.390368096356\n",
      "\n",
      "Training with alpha=0.6, lambda=0.1, epsilon=0.0009118819655545166, layer=3, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170270.65510437565\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149611.57976191933\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 144544.79209064168\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 139259.4359262137\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 121998.08242220794\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 103051.89720950974\n",
      "Processing fold 7...\n",
      "Converged at epoch 974\n",
      "MAE for fold 7: 101765.01006177982\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 104388.37165151435\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 101271.17357199384\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 102814.0322808944\n",
      "Mean MAE: 123897.50300810506\n",
      "\n",
      "Training with alpha=0.6, lambda=0.1, epsilon=0.0009118819655545166, layer=3, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159771.56753267752\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 128697.3933105361\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 113140.42755703177\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 99615.46316802032\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 74434.62119594953\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 55686.96438330487\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 61738.61296062444\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 56984.83439685778\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 50460.27365328417\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 49740.15969815418\n",
      "Mean MAE: 85027.03178564405\n",
      "\n",
      "Training with alpha=0.6, lambda=0.1, epsilon=0.0009118819655545166, layer=3, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138889.55864311566\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89225.27652566755\n",
      "Processing fold 3...\n",
      "Converged at epoch 971\n",
      "MAE for fold 3: 60375.038780994895\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 47227.79518086062\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 29123.017224151397\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 22040.089152171186\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 24455.897152724596\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 24089.426735030644\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 23255.953764716425\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 23209.991944082485\n",
      "Mean MAE: 48189.20451035154\n",
      "\n",
      "Training with alpha=0.6, lambda=0.1, epsilon=0.0009118819655545166, layer=5, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170268.65832725086\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149609.58298479457\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 144542.79531351698\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 139257.43914908898\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 121996.11299819459\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 103050.95719922398\n",
      "Processing fold 7...\n",
      "Converged at epoch 974\n",
      "MAE for fold 7: 101764.67639819157\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 104388.23019222595\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 101271.12083556876\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 102814.0117820883\n",
      "Mean MAE: 123896.35851801446\n",
      "\n",
      "Training with alpha=0.6, lambda=0.1, epsilon=0.0009118819655545166, layer=5, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159768.8976657016\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 128694.76001708118\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 113137.79426357683\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 99613.23218328769\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 74432.71937289878\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 55686.53396616196\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 61738.494174480526\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 56984.676899147584\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 55541.71562976133\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 54142.099764354636\n",
      "Mean MAE: 85974.09239364522\n",
      "\n",
      "Training with alpha=0.6, lambda=0.1, epsilon=0.0009118819655545166, layer=5, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138889.63305748274\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89225.34060470504\n",
      "Processing fold 3...\n",
      "Converged at epoch 971\n",
      "MAE for fold 3: 60375.07495464475\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 60396.44055312577\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 38580.03679081623\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 24926.564455162526\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 26946.059949663806\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 23712.545109786137\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 22641.487389617967\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 21088.479170115614\n",
      "Mean MAE: 50678.16620351205\n",
      "\n",
      "Training with alpha=0.6, lambda=0.1, epsilon=0.0009118819655545166, layer=10, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170269.15141468472\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149610.07607222837\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 144543.28840095084\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 139257.93223652284\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 121996.599331006\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 103051.18931009046\n",
      "Processing fold 7...\n",
      "Converged at epoch 974\n",
      "MAE for fold 7: 101764.75878765644\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 104388.26512188403\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 101271.13385744483\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 102814.01684373066\n",
      "Mean MAE: 123896.64113761992\n",
      "\n",
      "Training with alpha=0.6, lambda=0.1, epsilon=0.0009118819655545166, layer=10, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159770.93428974063\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 128696.76874215921\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 113139.80298865486\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 99614.93401981212\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 74434.17011878849\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 55686.86231615556\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 61738.5847922227\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 56984.53471033998\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 55541.443194429696\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 54141.84187305492\n",
      "Mean MAE: 85974.98770453583\n",
      "\n",
      "Training with alpha=0.6, lambda=0.1, epsilon=0.0009118819655545166, layer=10, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138890.6538461731\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89226.21961718901\n",
      "Processing fold 3...\n",
      "Converged at epoch 971\n",
      "MAE for fold 3: 60375.57117137\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 60394.08247278059\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 53741.55343327243\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 52973.39236825176\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 64133.076212510874\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 55401.83532942345\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 55691.1158121287\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 52696.6791649773\n",
      "Mean MAE: 68352.4179428077\n",
      "\n",
      "Training with alpha=0.6, lambda=0.1, epsilon=0.0024787521766663594, layer=1, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170276.98571770042\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149617.91037524186\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 144551.12270396375\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 139265.76653955661\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 122004.32631479745\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 103054.88079854457\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 101611.62656964769\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 104366.83255066446\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 101172.90152504797\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 102810.8996388373\n",
      "Mean MAE: 123873.3252734002\n",
      "\n",
      "Training with alpha=0.6, lambda=0.1, epsilon=0.0024787521766663594, layer=1, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 160245.89632837102\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 129165.22445149001\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 113608.2586979869\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 100029.10023375564\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 73573.32466766331\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 52764.50729580719\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 53805.90882833214\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 53011.73463862965\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 50206.24002168788\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 49645.45593565628\n",
      "Mean MAE: 83605.565109938\n",
      "\n",
      "Training with alpha=0.6, lambda=0.1, epsilon=0.0024787521766663594, layer=1, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138888.1151233205\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89224.03349471981\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 58052.006812159685\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 45018.281012297084\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 27499.226887788926\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 23910.173724057036\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 24741.00634662874\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 21496.803541103236\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 19915.18163655223\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 20186.929801688082\n",
      "Mean MAE: 46893.17583803153\n",
      "\n",
      "Training with alpha=0.6, lambda=0.1, epsilon=0.0024787521766663594, layer=3, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170268.51198695932\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149609.43664450303\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 144542.64897322538\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 139257.29280879739\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 121995.96866256445\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 103050.88855465433\n",
      "Processing fold 7...\n",
      "Converged at epoch 952\n",
      "MAE for fold 7: 101811.46057681844\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 104408.0647107243\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 101278.51520047642\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 102816.88599380189\n",
      "Mean MAE: 123903.96741125251\n",
      "\n",
      "Training with alpha=0.6, lambda=0.1, epsilon=0.0024787521766663594, layer=3, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159770.1500930798\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 128695.99528791918\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 113139.02953441482\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 99614.27873219206\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 74433.6115129484\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 55686.73585844951\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 61738.549892536146\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 56984.52058996077\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 53873.09257071846\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 50000.95212218147\n",
      "Mean MAE: 85393.69161944005\n",
      "\n",
      "Training with alpha=0.6, lambda=0.1, epsilon=0.0024787521766663594, layer=3, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138890.5131364733\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89226.09845050177\n",
      "Processing fold 3...\n",
      "Converged at epoch 971\n",
      "MAE for fold 3: 60375.50277082066\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 48834.03985710035\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 31855.072334089138\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 24324.0558221339\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 25140.861706974832\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 22824.750061472227\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 22602.53319734326\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 19498.570130069947\n",
      "Mean MAE: 48357.199746697945\n",
      "\n",
      "Training with alpha=0.6, lambda=0.1, epsilon=0.0024787521766663594, layer=5, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170268.31999115666\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149609.2446487003\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 144542.45697742276\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 139257.10081299476\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 121995.77929684131\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 103050.79778856364\n",
      "Processing fold 7...\n",
      "Converged at epoch 952\n",
      "MAE for fold 7: 101811.4276718199\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 104408.05076039283\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 101278.50999975314\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 102816.88397226561\n",
      "Mean MAE: 123903.85719199109\n",
      "\n",
      "Training with alpha=0.6, lambda=0.1, epsilon=0.0024787521766663594, layer=5, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159770.55110199683\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 128696.39080356342\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 113139.42505005904\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 99614.61382183514\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 74433.89716313593\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 55686.80051464265\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 61738.567736295496\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 56984.78945222743\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 55541.54083809875\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 54142.09617269669\n",
      "Mean MAE: 85974.86726545513\n",
      "\n",
      "Training with alpha=0.6, lambda=0.1, epsilon=0.0024787521766663594, layer=5, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138890.36809580907\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89225.97355437552\n",
      "Processing fold 3...\n",
      "Converged at epoch 971\n",
      "MAE for fold 3: 60375.43226494305\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 60394.328484786674\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 38788.10519402676\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 26174.968504847893\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 25082.093661139686\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 25821.980953043843\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 21696.80228936441\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 23302.358898608545\n",
      "Mean MAE: 50975.241190094544\n",
      "\n",
      "Training with alpha=0.6, lambda=0.1, epsilon=0.0024787521766663594, layer=10, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170269.5436190013\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149610.46827654497\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 144543.68060526744\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 139258.32444083938\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 121996.98616266072\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 103051.37388909115\n",
      "Processing fold 7...\n",
      "Converged at epoch 952\n",
      "MAE for fold 7: 101811.63652280165\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 104408.13930440038\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 101278.54300921143\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 102816.89680314058\n",
      "Mean MAE: 123904.55926329592\n",
      "\n",
      "Training with alpha=0.6, lambda=0.1, epsilon=0.0024787521766663594, layer=10, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159770.5063345007\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 128696.34664932067\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 113139.3808958163\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 99614.57641337944\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 74433.86527396065\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 55686.79329661283\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 61738.56574427005\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 56984.527003557065\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 55541.44024038633\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 54141.984027597355\n",
      "Mean MAE: 85974.79858794014\n",
      "\n",
      "Training with alpha=0.6, lambda=0.1, epsilon=0.0024787521766663594, layer=10, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138892.28147155305\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89227.62118348795\n",
      "Processing fold 3...\n",
      "Converged at epoch 971\n",
      "MAE for fold 3: 60376.36237815155\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 60393.07150120325\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 53738.993711167386\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 52981.31794832743\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 64104.11701886093\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 55400.08919209166\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 55668.55463212244\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 52712.55980404185\n",
      "Mean MAE: 68349.49688410075\n",
      "\n",
      "Training with alpha=0.6, lambda=0.1, epsilon=0.006737946999085469, layer=1, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 171095.26263473963\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 150436.1872922823\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 145369.39962100703\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 140084.04345659955\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 122811.39395900453\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 103500.3714993732\n",
      "Processing fold 7...\n",
      "Converged at epoch 984\n",
      "MAE for fold 7: 101901.72423475415\n",
      "Processing fold 8...\n",
      "Converged at epoch 581\n",
      "MAE for fold 8: 105008.18987190622\n",
      "Processing fold 9...\n",
      "Converged at epoch 108\n",
      "MAE for fold 9: 102131.40771909343\n",
      "Processing fold 10...\n",
      "Converged at epoch 674\n",
      "MAE for fold 10: 103281.34912768644\n",
      "Mean MAE: 124561.93294164464\n",
      "\n",
      "Training with alpha=0.6, lambda=0.1, epsilon=0.006737946999085469, layer=1, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159771.24315116342\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 128697.07337259999\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 113140.10761909529\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 99664.08252843114\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 73558.60424655098\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 53653.80306476949\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 53619.745022300725\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 53802.89806036657\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 51191.908678702675\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 49732.501979764005\n",
      "Mean MAE: 83683.19677237442\n",
      "\n",
      "Training with alpha=0.6, lambda=0.1, epsilon=0.006737946999085469, layer=1, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138896.3672188548\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89231.13946587467\n",
      "Processing fold 3...\n",
      "Converged at epoch 471\n",
      "MAE for fold 3: 76265.30544412445\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 53948.532169296406\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 32110.56473974088\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 26219.994887800996\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 24940.536954075098\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 20615.376115410527\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 19359.634030525147\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 20499.503747553164\n",
      "Mean MAE: 50208.695477325615\n",
      "\n",
      "Training with alpha=0.6, lambda=0.1, epsilon=0.006737946999085469, layer=3, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170267.23456646616\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149608.15922400975\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 144541.3715527322\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 139256.0153883042\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 121994.70874098214\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 103050.28699394118\n",
      "Processing fold 7...\n",
      "Converged at epoch 899\n",
      "MAE for fold 7: 101928.13640476216\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 104457.53034067812\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 101296.9561280092\n",
      "Processing fold 10...\n",
      "Converged at epoch 825\n",
      "MAE for fold 10: 102850.36942172654\n",
      "Mean MAE: 123925.07687616115\n",
      "\n",
      "Training with alpha=0.6, lambda=0.1, epsilon=0.006737946999085469, layer=3, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159769.00613222813\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 128694.86699776408\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 113137.90124425969\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 99613.32281969949\n",
      "Processing fold 5...\n",
      "Converged at epoch 757\n",
      "MAE for fold 5: 78551.20326803664\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 56780.18591372623\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 62044.25380609472\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 57097.76582044491\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 51619.01890259231\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 49496.0668819776\n",
      "Mean MAE: 85680.35917868238\n",
      "\n",
      "Training with alpha=0.6, lambda=0.1, epsilon=0.006737946999085469, layer=3, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138889.6340915793\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89225.34149517638\n",
      "Processing fold 3...\n",
      "Converged at epoch 971\n",
      "MAE for fold 3: 60375.07545733056\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 47420.82303930349\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 29510.53940156783\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 23692.578365946418\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 27244.683011442914\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 25613.18865241918\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 22367.261075010123\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 21108.08284390368\n",
      "Mean MAE: 48544.72074336799\n",
      "\n",
      "Training with alpha=0.6, lambda=0.1, epsilon=0.006737946999085469, layer=5, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170271.036226227\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149611.96088377078\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 144545.1732124932\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 139259.81704806516\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 121998.45832321217\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 103052.07675083606\n",
      "Processing fold 7...\n",
      "Converged at epoch 899\n",
      "MAE for fold 7: 101928.8190647914\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 104457.81975973803\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 101297.06402425795\n",
      "Processing fold 10...\n",
      "Converged at epoch 825\n",
      "MAE for fold 10: 102850.41897674168\n",
      "Mean MAE: 123927.26442701335\n",
      "\n",
      "Training with alpha=0.6, lambda=0.1, epsilon=0.006737946999085469, layer=5, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159767.9035491256\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 128693.7795185385\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 113136.81376503414\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 99612.40148313345\n",
      "Processing fold 5...\n",
      "Converged at epoch 757\n",
      "MAE for fold 5: 78550.34234698309\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 56779.93487285604\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 62044.185073913926\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 57097.979465283235\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 55584.92706051875\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 54160.84384766392\n",
      "Mean MAE: 86542.91109830506\n",
      "\n",
      "Training with alpha=0.6, lambda=0.1, epsilon=0.006737946999085469, layer=5, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138890.65050645455\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89226.21674131886\n",
      "Processing fold 3...\n",
      "Converged at epoch 971\n",
      "MAE for fold 3: 60375.569547894884\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 60397.304576128285\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 31913.405214933468\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 26730.80736726966\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 29331.744221923134\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 24584.247691001292\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 23553.369124816443\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 21116.49147157878\n",
      "Mean MAE: 50611.980646331926\n",
      "\n",
      "Training with alpha=0.6, lambda=0.1, epsilon=0.006737946999085469, layer=10, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170270.61141428052\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149611.53607182414\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 144544.7484005466\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 139259.3922361186\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 121998.03933060731\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 103051.87663963989\n",
      "Processing fold 7...\n",
      "Converged at epoch 899\n",
      "MAE for fold 7: 101928.74273715413\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 104457.78740003919\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 101297.05196047031\n",
      "Processing fold 10...\n",
      "Converged at epoch 825\n",
      "MAE for fold 10: 102850.4134360376\n",
      "Mean MAE: 123927.01996267182\n",
      "\n",
      "Training with alpha=0.6, lambda=0.1, epsilon=0.006737946999085469, layer=10, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159767.31485452756\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 128693.19888825122\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 113136.23313474681\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 99611.9095602512\n",
      "Processing fold 5...\n",
      "Converged at epoch 757\n",
      "MAE for fold 5: 78549.882681339\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 56779.800779030425\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 62044.14836052504\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 57097.72742358867\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 55584.83045184526\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 54160.22297825262\n",
      "Mean MAE: 86542.52691123578\n",
      "\n",
      "Training with alpha=0.6, lambda=0.1, epsilon=0.006737946999085469, layer=10, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138888.06150795796\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89223.98732594763\n",
      "Processing fold 3...\n",
      "Converged at epoch 971\n",
      "MAE for fold 3: 60374.31100695956\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 60397.448409378616\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 53744.96060037948\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 52937.45711786836\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 64155.14693133283\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 55405.31941242439\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 55689.62675887059\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 52691.3605081351\n",
      "Mean MAE: 68350.76795792545\n",
      "\n",
      "Training with alpha=0.6, lambda=0.2, epsilon=0.0009118819655545166, layer=1, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170271.4342550313\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149612.35891257215\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 146017.20146953594\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 150692.64570765238\n",
      "Processing fold 5...\n",
      "Converged at epoch 304\n",
      "MAE for fold 5: 145505.36085504267\n",
      "Processing fold 6...\n",
      "Converged at epoch 1\n",
      "MAE for fold 6: 136537.96674403083\n",
      "Processing fold 7...\n",
      "Converged at epoch 205\n",
      "MAE for fold 7: 137126.50148256842\n",
      "Processing fold 8...\n",
      "Converged at epoch 1\n",
      "MAE for fold 8: 143046.70502158641\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 140147.2624468141\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 141906.2881064956\n",
      "Mean MAE: 146086.372500133\n",
      "\n",
      "Training with alpha=0.6, lambda=0.2, epsilon=0.0009118819655545166, layer=1, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 160281.25598193813\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 129200.0997262395\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 116086.1422737427\n",
      "Processing fold 4...\n",
      "Converged at epoch 551\n",
      "MAE for fold 4: 120052.71194910139\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 113153.32576285997\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 103605.336992468\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 105490.23248519024\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 110028.40921588198\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 107275.99641864533\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 109114.07840257775\n",
      "Mean MAE: 117428.75892086448\n",
      "\n",
      "Training with alpha=0.6, lambda=0.2, epsilon=0.0009118819655545166, layer=1, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138922.39680261584\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89137.21948352591\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 61194.393447902985\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 63873.51483635777\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 56975.014788901906\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 50728.75626454289\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 54749.1517943109\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 55947.65127884177\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 54569.38680817759\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 53406.512898835674\n",
      "Mean MAE: 67950.39984040133\n",
      "\n",
      "Training with alpha=0.6, lambda=0.2, epsilon=0.0009118819655545166, layer=3, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170270.17311334837\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149611.09777089304\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 146016.60613022005\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 150692.5582428879\n",
      "Processing fold 5...\n",
      "Converged at epoch 304\n",
      "MAE for fold 5: 145505.31212590708\n",
      "Processing fold 6...\n",
      "Converged at epoch 1\n",
      "MAE for fold 6: 136537.9182014427\n",
      "Processing fold 7...\n",
      "Converged at epoch 205\n",
      "MAE for fold 7: 137126.46967911028\n",
      "Processing fold 8...\n",
      "Converged at epoch 1\n",
      "MAE for fold 8: 143046.67244744496\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 140147.229997376\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 141906.2557812938\n",
      "Mean MAE: 146086.02934899242\n",
      "\n",
      "Training with alpha=0.6, lambda=0.2, epsilon=0.0009118819655545166, layer=3, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159772.31716784547\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 128698.13267673139\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 115802.64012624933\n",
      "Processing fold 4...\n",
      "Converged at epoch 516\n",
      "MAE for fold 4: 120088.0831967452\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 113158.67083139649\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 103481.12760884708\n",
      "Processing fold 7...\n",
      "Converged at epoch 466\n",
      "MAE for fold 7: 105587.54861282026\n",
      "Processing fold 8...\n",
      "Converged at epoch 137\n",
      "MAE for fold 8: 110041.66391544281\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 107331.25082580668\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 109173.0603036786\n",
      "Mean MAE: 117313.44952655633\n",
      "\n",
      "Training with alpha=0.6, lambda=0.2, epsilon=0.0009118819655545166, layer=3, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138889.59967816118\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89225.31186140685\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 62614.076699721496\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 67458.6952714596\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 61800.78293891024\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 54271.85842719049\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 62357.90348558028\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 58558.22870986565\n",
      "Processing fold 9...\n",
      "Converged at epoch 2\n",
      "MAE for fold 9: 57342.88475211247\n",
      "Processing fold 10...\n",
      "Converged at epoch 4\n",
      "MAE for fold 10: 56394.38465066603\n",
      "Mean MAE: 70891.37264750742\n",
      "\n",
      "Training with alpha=0.6, lambda=0.2, epsilon=0.0009118819655545166, layer=5, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170267.68276481525\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149608.60742235993\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 146015.43387846084\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 150692.3860206088\n",
      "Processing fold 5...\n",
      "Converged at epoch 303\n",
      "MAE for fold 5: 145505.70202112186\n",
      "Processing fold 6...\n",
      "Converged at epoch 1\n",
      "MAE for fold 6: 136538.30660396538\n",
      "Processing fold 7...\n",
      "Converged at epoch 206\n",
      "MAE for fold 7: 137126.40705653402\n",
      "Processing fold 8...\n",
      "Converged at epoch 1\n",
      "MAE for fold 8: 143046.60830735302\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 140147.16610284086\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 141906.1921313753\n",
      "Mean MAE: 146085.44923094352\n",
      "\n",
      "Training with alpha=0.6, lambda=0.2, epsilon=0.0009118819655545166, layer=5, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159769.8735009572\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 128695.72248473202\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 115801.50517011156\n",
      "Processing fold 4...\n",
      "Converged at epoch 516\n",
      "MAE for fold 4: 120087.67382392545\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 113158.60896968946\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 103481.11839415751\n",
      "Processing fold 7...\n",
      "Converged at epoch 466\n",
      "MAE for fold 7: 105587.54510782279\n",
      "Processing fold 8...\n",
      "Converged at epoch 136\n",
      "MAE for fold 8: 110041.6883446347\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 107331.27482810745\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 109173.08421408798\n",
      "Mean MAE: 117312.80948382262\n",
      "\n",
      "Training with alpha=0.6, lambda=0.2, epsilon=0.0009118819655545166, layer=5, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138890.4064891961\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89226.00661535369\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 62614.324813391264\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 67458.72551870868\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 61800.78635721713\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 54271.76988541011\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 62357.88910811397\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 58558.225591743176\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 57342.882574966636\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 56394.38394405991\n",
      "Mean MAE: 70891.54008981606\n",
      "\n",
      "Training with alpha=0.6, lambda=0.2, epsilon=0.0009118819655545166, layer=10, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170268.3060975654\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149609.23075511007\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 146015.72744335202\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 150692.42914992315\n",
      "Processing fold 5...\n",
      "Converged at epoch 304\n",
      "MAE for fold 5: 145505.24020445484\n",
      "Processing fold 6...\n",
      "Converged at epoch 1\n",
      "MAE for fold 6: 136537.8465553377\n",
      "Processing fold 7...\n",
      "Converged at epoch 205\n",
      "MAE for fold 7: 137126.42273899267\n",
      "Processing fold 8...\n",
      "Converged at epoch 1\n",
      "MAE for fold 8: 143046.62436984034\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 140147.18210383385\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 141906.20807110943\n",
      "Mean MAE: 146085.52174895193\n",
      "\n",
      "Training with alpha=0.6, lambda=0.2, epsilon=0.0009118819655545166, layer=10, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159771.42120321884\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 128697.24898559279\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 115802.22378761554\n",
      "Processing fold 4...\n",
      "Converged at epoch 516\n",
      "MAE for fold 4: 120087.93302554928\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 113158.64813852088\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 103481.12422860065\n",
      "Processing fold 7...\n",
      "Converged at epoch 467\n",
      "MAE for fold 7: 105587.51423032812\n",
      "Processing fold 8...\n",
      "Converged at epoch 135\n",
      "MAE for fold 8: 110041.69017656415\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 107331.27662802457\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 109173.08600711424\n",
      "Mean MAE: 117313.2166411129\n",
      "\n",
      "Training with alpha=0.6, lambda=0.2, epsilon=0.0009118819655545166, layer=10, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138889.13879378303\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89224.91498874799\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 62613.935194716214\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 67458.67802074918\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 61800.78098937129\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 54271.76938595007\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 62357.889027011326\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 58558.22557415407\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 57342.88255970576\n",
      "Processing fold 10...\n",
      "Converged at epoch 2\n",
      "MAE for fold 10: 56394.38330853092\n",
      "Mean MAE: 70891.25978427197\n",
      "\n",
      "Training with alpha=0.6, lambda=0.2, epsilon=0.0024787521766663594, layer=1, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170279.9410782387\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149620.86573577963\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 146021.2350059258\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 150693.23829778875\n",
      "Processing fold 5...\n",
      "Converged at epoch 163\n",
      "MAE for fold 5: 145584.42436605596\n",
      "Processing fold 6...\n",
      "Converged at epoch 1\n",
      "MAE for fold 6: 136616.7275647932\n",
      "Processing fold 7...\n",
      "Converged at epoch 131\n",
      "MAE for fold 7: 137211.1733032081\n",
      "Processing fold 8...\n",
      "Converged at epoch 1\n",
      "MAE for fold 8: 143133.42867127628\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 140233.65407983807\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 141992.3489939613\n",
      "Mean MAE: 146138.70370968658\n",
      "\n",
      "Training with alpha=0.6, lambda=0.2, epsilon=0.0024787521766663594, layer=1, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 160198.22935306633\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 129118.21044844769\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 116041.12578913411\n",
      "Processing fold 4...\n",
      "Converged at epoch 539\n",
      "MAE for fold 4: 120083.32550397643\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 113157.95188035356\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 103661.44378929808\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 105505.6386455171\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 110028.56260772762\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 107272.63777745495\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 109117.65064149795\n",
      "Mean MAE: 117418.47764364738\n",
      "\n",
      "Training with alpha=0.6, lambda=0.2, epsilon=0.0024787521766663594, layer=1, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 139157.88991868513\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89511.901977317\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 61565.684808613965\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 64284.43261977277\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 57432.53458954268\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 50519.63303537439\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 55188.73029374737\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 55056.74975985079\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 53618.92489214563\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 53042.193931931004\n",
      "Mean MAE: 67937.86758269809\n",
      "\n",
      "Training with alpha=0.6, lambda=0.2, epsilon=0.0024787521766663594, layer=3, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170271.2907471922\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149612.21540473687\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 146017.13241573912\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 150692.63556253441\n",
      "Processing fold 5...\n",
      "Converged at epoch 162\n",
      "MAE for fold 5: 145584.62135124797\n",
      "Processing fold 6...\n",
      "Converged at epoch 1\n",
      "MAE for fold 6: 136616.9237958287\n",
      "Processing fold 7...\n",
      "Converged at epoch 131\n",
      "MAE for fold 7: 137211.32147183362\n",
      "Processing fold 8...\n",
      "Converged at epoch 1\n",
      "MAE for fold 8: 143133.58043043248\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 140233.805257988\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 141992.49959333934\n",
      "Mean MAE: 146136.60260308726\n",
      "\n",
      "Training with alpha=0.6, lambda=0.2, epsilon=0.0024787521766663594, layer=3, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159769.3691967439\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 128695.22508879555\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 115801.27112272239\n",
      "Processing fold 4...\n",
      "Converged at epoch 510\n",
      "MAE for fold 4: 120110.93534851681\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 113162.12409709861\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 103481.64199444202\n",
      "Processing fold 7...\n",
      "Converged at epoch 1\n",
      "MAE for fold 7: 105612.89397537583\n",
      "Processing fold 8...\n",
      "Converged at epoch 80\n",
      "MAE for fold 8: 110066.60208346421\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 107355.75320856816\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 109197.4688804315\n",
      "Mean MAE: 117325.32849961589\n",
      "\n",
      "Training with alpha=0.6, lambda=0.2, epsilon=0.0024787521766663594, layer=3, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138888.2115219609\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89224.11650467884\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 62613.65013035981\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 67458.64326888474\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 61800.77706198826\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 54271.76902051878\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 62357.88896767162\n",
      "Processing fold 8...\n",
      "Converged at epoch 480\n",
      "MAE for fold 8: 58558.76220169972\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 57343.34815562853\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 56394.933630830354\n",
      "Mean MAE: 70891.21004642217\n",
      "\n",
      "Training with alpha=0.6, lambda=0.2, epsilon=0.0024787521766663594, layer=5, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170270.8377850961\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149611.76244264087\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 146016.9192117373\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 150692.6042395026\n",
      "Processing fold 5...\n",
      "Converged at epoch 162\n",
      "MAE for fold 5: 145584.59843750976\n",
      "Processing fold 6...\n",
      "Converged at epoch 1\n",
      "MAE for fold 6: 136616.90096981445\n",
      "Processing fold 7...\n",
      "Converged at epoch 131\n",
      "MAE for fold 7: 137211.3042365431\n",
      "Processing fold 8...\n",
      "Converged at epoch 1\n",
      "MAE for fold 8: 143133.56277748398\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 140233.7876726228\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 141992.4820752987\n",
      "Mean MAE: 146136.475984825\n",
      "\n",
      "Training with alpha=0.6, lambda=0.2, epsilon=0.0024787521766663594, layer=5, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159768.7339646365\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 128694.5985584979\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 115800.97612224144\n",
      "Processing fold 4...\n",
      "Converged at epoch 510\n",
      "MAE for fold 4: 120110.8277118501\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 113162.10783175904\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 103481.63957161762\n",
      "Processing fold 7...\n",
      "Converged at epoch 1\n",
      "MAE for fold 7: 105612.89172713867\n",
      "Processing fold 8...\n",
      "Converged at epoch 80\n",
      "MAE for fold 8: 110066.6000171869\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 107355.75117839826\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 109197.46685803407\n",
      "Mean MAE: 117325.15935413605\n",
      "\n",
      "Training with alpha=0.6, lambda=0.2, epsilon=0.0024787521766663594, layer=5, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138890.64936310358\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89226.21575677405\n",
      "Processing fold 3...\n",
      "Converged at epoch 446\n",
      "MAE for fold 3: 77358.529245402\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 69152.19867846201\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 61982.08255131192\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 54288.63889062429\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 62360.82578859634\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 58558.86248629686\n",
      "Processing fold 9...\n",
      "Converged at epoch 52\n",
      "MAE for fold 9: 57343.35823760321\n",
      "Processing fold 10...\n",
      "Converged at epoch 5\n",
      "MAE for fold 10: 56394.93877919711\n",
      "Mean MAE: 72555.62997773713\n",
      "\n",
      "Training with alpha=0.6, lambda=0.2, epsilon=0.0024787521766663594, layer=10, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170268.57761775499\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149609.5022752997\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 146015.85544775208\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 150692.44795578922\n",
      "Processing fold 5...\n",
      "Converged at epoch 162\n",
      "MAE for fold 5: 145584.48411128108\n",
      "Processing fold 6...\n",
      "Converged at epoch 1\n",
      "MAE for fold 6: 136616.78708127738\n",
      "Processing fold 7...\n",
      "Converged at epoch 131\n",
      "MAE for fold 7: 137211.2182424667\n",
      "Processing fold 8...\n",
      "Converged at epoch 1\n",
      "MAE for fold 8: 143133.4746995366\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 140233.69993187694\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 141992.39467046343\n",
      "Mean MAE: 146135.8442033498\n",
      "\n",
      "Training with alpha=0.6, lambda=0.2, epsilon=0.0024787521766663594, layer=10, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159767.87018816615\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 128693.74661458192\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 115800.57531007053\n",
      "Processing fold 4...\n",
      "Converged at epoch 510\n",
      "MAE for fold 4: 120110.68146772926\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 113162.08573231693\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 103481.63627976712\n",
      "Processing fold 7...\n",
      "Converged at epoch 1\n",
      "MAE for fold 7: 105612.88867249686\n",
      "Processing fold 8...\n",
      "Converged at epoch 80\n",
      "MAE for fold 8: 110066.59720977084\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 107355.74842004075\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 109197.46411023678\n",
      "Mean MAE: 117324.92940051772\n",
      "\n",
      "Training with alpha=0.6, lambda=0.2, epsilon=0.0024787521766663594, layer=10, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138890.21211674516\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89225.83923907542\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 62614.26501408783\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 67458.71822864524\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 61800.78553335167\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 54271.76980875223\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 62357.88909566623\n",
      "Processing fold 8...\n",
      "Converged at epoch 480\n",
      "MAE for fold 8: 58558.76227680887\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 57343.348220796106\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 56394.93370776993\n",
      "Mean MAE: 70891.65232416986\n",
      "\n",
      "Training with alpha=0.6, lambda=0.2, epsilon=0.006737946999085469, layer=1, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170269.40228622095\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149610.32694376176\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 146016.24312718856\n",
      "Processing fold 4...\n",
      "Converged at epoch 979\n",
      "MAE for fold 4: 150710.27236424372\n",
      "Processing fold 5...\n",
      "Converged at epoch 1\n",
      "MAE for fold 5: 145722.47164327855\n",
      "Processing fold 6...\n",
      "Converged at epoch 1\n",
      "MAE for fold 6: 136754.2463356979\n",
      "Processing fold 7...\n",
      "Converged at epoch 78\n",
      "MAE for fold 7: 137352.8620297691\n",
      "Processing fold 8...\n",
      "Converged at epoch 1\n",
      "MAE for fold 8: 143278.55090195977\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 140378.22071813844\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 142136.36216693395\n",
      "Mean MAE: 146222.89585171925\n",
      "\n",
      "Training with alpha=0.6, lambda=0.2, epsilon=0.006737946999085469, layer=1, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159774.60381827957\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 128700.388003178\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 115803.70664115556\n",
      "Processing fold 4...\n",
      "Converged at epoch 493\n",
      "MAE for fold 4: 120179.47803970396\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 113172.4818142153\n",
      "Processing fold 6...\n",
      "Converged at epoch 365\n",
      "MAE for fold 6: 103595.86011673402\n",
      "Processing fold 7...\n",
      "Converged at epoch 934\n",
      "MAE for fold 7: 105585.2354257905\n",
      "Processing fold 8...\n",
      "Converged at epoch 744\n",
      "MAE for fold 8: 110034.62126574262\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 107317.81950681329\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 109159.23927970274\n",
      "Mean MAE: 117332.34339113157\n",
      "\n",
      "Training with alpha=0.6, lambda=0.2, epsilon=0.006737946999085469, layer=1, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 139116.7674075901\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89438.78179623249\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 61145.45129954407\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 64185.95878189782\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 56961.8060108208\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 49721.86368928286\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 54489.805165602476\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 55125.58439857906\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 54130.40599865658\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 53105.48878835533\n",
      "Mean MAE: 67742.19133365616\n",
      "\n",
      "Training with alpha=0.6, lambda=0.2, epsilon=0.006737946999085469, layer=3, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170268.49433818032\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149609.41899572502\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 146015.81587050157\n",
      "Processing fold 4...\n",
      "Converged at epoch 979\n",
      "MAE for fold 4: 150710.20713894034\n",
      "Processing fold 5...\n",
      "Converged at epoch 1\n",
      "MAE for fold 5: 145722.40666772934\n",
      "Processing fold 6...\n",
      "Converged at epoch 1\n",
      "MAE for fold 6: 136754.1816088951\n",
      "Processing fold 7...\n",
      "Converged at epoch 78\n",
      "MAE for fold 7: 137352.80792719018\n",
      "Processing fold 8...\n",
      "Converged at epoch 1\n",
      "MAE for fold 8: 143278.49548832868\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 140378.16551665103\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 142136.30717678717\n",
      "Mean MAE: 146222.63007289288\n",
      "\n",
      "Training with alpha=0.6, lambda=0.2, epsilon=0.006737946999085469, layer=3, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159769.00552769843\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 128694.86640151782\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 115801.10217297527\n",
      "Processing fold 4...\n",
      "Converged at epoch 492\n",
      "MAE for fold 4: 120182.54313002841\n",
      "Processing fold 5...\n",
      "Converged at epoch 1\n",
      "MAE for fold 5: 115017.89328605136\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 103758.07045979792\n",
      "Processing fold 7...\n",
      "Converged at epoch 408\n",
      "MAE for fold 7: 105707.31659905298\n",
      "Processing fold 8...\n",
      "Converged at epoch 152\n",
      "MAE for fold 8: 110137.13768658305\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 107425.0562281183\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 109266.50657722869\n",
      "Mean MAE: 117575.9498069052\n",
      "\n",
      "Training with alpha=0.6, lambda=0.2, epsilon=0.006737946999085469, layer=3, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138887.85033169296\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89223.80547972592\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 62613.539156528306\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 67458.6297401939\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 61800.77553308183\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 54271.76887825908\n",
      "Processing fold 7...\n",
      "Converged at epoch 946\n",
      "MAE for fold 7: 62358.04414921569\n",
      "Processing fold 8...\n",
      "Converged at epoch 12\n",
      "MAE for fold 8: 58560.223044262806\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 57344.6156312685\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 56396.430073117735\n",
      "Mean MAE: 70891.56820173467\n",
      "\n",
      "Training with alpha=0.6, lambda=0.2, epsilon=0.006737946999085469, layer=5, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170269.51965005248\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149610.44430759718\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 146016.2989299259\n",
      "Processing fold 4...\n",
      "Converged at epoch 979\n",
      "MAE for fold 4: 150710.2808830999\n",
      "Processing fold 5...\n",
      "Converged at epoch 1\n",
      "MAE for fold 5: 145722.48012956348\n",
      "Processing fold 6...\n",
      "Converged at epoch 1\n",
      "MAE for fold 6: 136754.25478948464\n",
      "Processing fold 7...\n",
      "Converged at epoch 78\n",
      "MAE for fold 7: 137352.86909596747\n",
      "Processing fold 8...\n",
      "Converged at epoch 1\n",
      "MAE for fold 8: 143278.55813939226\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 140378.22792785848\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 142136.36934905683\n",
      "Mean MAE: 146222.93032019987\n",
      "\n",
      "Training with alpha=0.6, lambda=0.2, epsilon=0.006737946999085469, layer=5, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159768.6600355802\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 128694.52564216839\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 115800.94169048741\n",
      "Processing fold 4...\n",
      "Converged at epoch 492\n",
      "MAE for fold 4: 120182.48251812374\n",
      "Processing fold 5...\n",
      "Converged at epoch 1\n",
      "MAE for fold 5: 115017.8311810573\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 103758.06120886927\n",
      "Processing fold 7...\n",
      "Converged at epoch 408\n",
      "MAE for fold 7: 105707.31266624833\n",
      "Processing fold 8...\n",
      "Converged at epoch 152\n",
      "MAE for fold 8: 110137.13453827094\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 107425.05313482172\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 109266.5034957747\n",
      "Mean MAE: 117575.85061114021\n",
      "\n",
      "Training with alpha=0.6, lambda=0.2, epsilon=0.006737946999085469, layer=5, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138890.8729011914\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89226.40824790405\n",
      "Processing fold 3...\n",
      "Converged at epoch 446\n",
      "MAE for fold 3: 77358.71863183647\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 69152.22593109384\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 61982.08528120394\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 54288.639144631605\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 62360.628348491446\n",
      "Processing fold 8...\n",
      "Converged at epoch 512\n",
      "MAE for fold 8: 58560.22335240916\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 57344.615898626704\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 56396.4303887733\n",
      "Mean MAE: 72556.0848126162\n",
      "\n",
      "Training with alpha=0.6, lambda=0.2, epsilon=0.006737946999085469, layer=10, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170268.56975883435\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149609.49441637908\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 146015.85148922214\n",
      "Processing fold 4...\n",
      "Converged at epoch 979\n",
      "MAE for fold 4: 150710.212576517\n",
      "Processing fold 5...\n",
      "Converged at epoch 1\n",
      "MAE for fold 5: 145722.41208448855\n",
      "Processing fold 6...\n",
      "Converged at epoch 1\n",
      "MAE for fold 6: 136754.18700491652\n",
      "Processing fold 7...\n",
      "Converged at epoch 78\n",
      "MAE for fold 7: 137352.8124375124\n",
      "Processing fold 8...\n",
      "Converged at epoch 1\n",
      "MAE for fold 8: 143278.50010794838\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 140378.1701185847\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 142136.3117611026\n",
      "Mean MAE: 146222.65217555058\n",
      "\n",
      "Training with alpha=0.6, lambda=0.2, epsilon=0.006737946999085469, layer=10, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159770.45887966926\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 128696.29984455765\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 115801.77699953344\n",
      "Processing fold 4...\n",
      "Converged at epoch 492\n",
      "MAE for fold 4: 120182.79800221825\n",
      "Processing fold 5...\n",
      "Converged at epoch 1\n",
      "MAE for fold 5: 115018.15443666083\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 103758.10935981988\n",
      "Processing fold 7...\n",
      "Converged at epoch 408\n",
      "MAE for fold 7: 105707.33313644\n",
      "Processing fold 8...\n",
      "Converged at epoch 152\n",
      "MAE for fold 8: 110137.15092519061\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 107425.06923538602\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 109266.5195346989\n",
      "Mean MAE: 117576.3670354175\n",
      "\n",
      "Training with alpha=0.6, lambda=0.2, epsilon=0.006737946999085469, layer=10, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138889.7076907726\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89225.40487226578\n",
      "Processing fold 3...\n",
      "Converged at epoch 446\n",
      "MAE for fold 3: 77357.7314396762\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 69152.08376205656\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 61982.07104015289\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 54288.637819549476\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 62360.62813332389\n",
      "Processing fold 8...\n",
      "Converged at epoch 512\n",
      "MAE for fold 8: 58560.22323366127\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 57344.61579559709\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 56396.43026713158\n",
      "Mean MAE: 72555.75340541873\n",
      "\n",
      "Training with alpha=0.6, lambda=0.3, epsilon=0.0009118819655545166, layer=1, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170300.143972278\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 150606.72400615644\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 156180.40813444392\n",
      "Processing fold 4...\n",
      "Converged at epoch 86\n",
      "MAE for fold 4: 163469.16244732193\n",
      "Processing fold 5...\n",
      "Converged at epoch 1\n",
      "MAE for fold 5: 158482.64701719664\n",
      "Processing fold 6...\n",
      "Converged at epoch 1\n",
      "MAE for fold 6: 149515.70307672294\n",
      "Processing fold 7...\n",
      "Converged at epoch 1\n",
      "MAE for fold 7: 150107.96759495864\n",
      "Processing fold 8...\n",
      "Converged at epoch 1\n",
      "MAE for fold 8: 156106.39260963883\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 153207.08769280626\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 154966.25145768115\n",
      "Mean MAE: 156294.2488009205\n",
      "\n",
      "Training with alpha=0.6, lambda=0.3, epsilon=0.0009118819655545166, layer=1, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159782.02676312422\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 130476.42026428618\n",
      "Processing fold 3...\n",
      "Converged at epoch 778\n",
      "MAE for fold 3: 134566.0851853964\n",
      "Processing fold 4...\n",
      "Converged at epoch 1\n",
      "MAE for fold 4: 141878.41919157628\n",
      "Processing fold 5...\n",
      "Converged at epoch 58\n",
      "MAE for fold 5: 136946.9518469637\n",
      "Processing fold 6...\n",
      "Converged at epoch 1\n",
      "MAE for fold 6: 127861.57267936008\n",
      "Processing fold 7...\n",
      "Converged at epoch 69\n",
      "MAE for fold 7: 128708.30860091164\n",
      "Processing fold 8...\n",
      "Converged at epoch 606\n",
      "MAE for fold 8: 134165.32730595075\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 131266.25799297137\n",
      "Processing fold 10...\n",
      "Converged at epoch 4\n",
      "MAE for fold 10: 133025.24912244623\n",
      "Mean MAE: 135867.6618952987\n",
      "\n",
      "Training with alpha=0.6, lambda=0.3, epsilon=0.0009118819655545166, layer=1, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138930.35151910153\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 92129.28688442604\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 91844.35220359138\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 100091.64793972786\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 93665.2641976959\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 84805.67316011807\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 87502.30071088595\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 91210.9989541276\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 88457.24981275879\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 89674.86386650965\n",
      "Mean MAE: 95831.19892489426\n",
      "\n",
      "Training with alpha=0.6, lambda=0.3, epsilon=0.0009118819655545166, layer=3, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170268.01485143852\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 150591.43241230823\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 156179.5470874185\n",
      "Processing fold 4...\n",
      "Converged at epoch 84\n",
      "MAE for fold 4: 163469.01348317412\n",
      "Processing fold 5...\n",
      "Converged at epoch 1\n",
      "MAE for fold 5: 158482.49890771712\n",
      "Processing fold 6...\n",
      "Converged at epoch 1\n",
      "MAE for fold 6: 149515.55581697973\n",
      "Processing fold 7...\n",
      "Converged at epoch 1\n",
      "MAE for fold 7: 150107.82118009974\n",
      "Processing fold 8...\n",
      "Converged at epoch 1\n",
      "MAE for fold 8: 156106.2470348067\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 153206.94295317456\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 154966.10754847043\n",
      "Mean MAE: 156289.31812755874\n",
      "\n",
      "Training with alpha=0.6, lambda=0.3, epsilon=0.0009118819655545166, layer=3, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159770.19687066472\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 130470.88344276961\n",
      "Processing fold 3...\n",
      "Converged at epoch 777\n",
      "MAE for fold 3: 134566.64640973284\n",
      "Processing fold 4...\n",
      "Converged at epoch 1\n",
      "MAE for fold 4: 141878.97719596815\n",
      "Processing fold 5...\n",
      "Converged at epoch 59\n",
      "MAE for fold 5: 136946.45782897042\n",
      "Processing fold 6...\n",
      "Converged at epoch 1\n",
      "MAE for fold 6: 127861.07467366666\n",
      "Processing fold 7...\n",
      "Converged at epoch 68\n",
      "MAE for fold 7: 128708.68090546591\n",
      "Processing fold 8...\n",
      "Converged at epoch 608\n",
      "MAE for fold 8: 134165.11889739247\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 131266.05078011012\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 133025.4499859581\n",
      "Mean MAE: 135865.95369906988\n",
      "\n",
      "Training with alpha=0.6, lambda=0.3, epsilon=0.0009118819655545166, layer=3, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138890.05533446922\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 92183.00343146226\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 91696.66567715384\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 99983.68795652504\n",
      "Processing fold 5...\n",
      "Converged at epoch 765\n",
      "MAE for fold 5: 93887.02337629386\n",
      "Processing fold 6...\n",
      "Converged at epoch 1\n",
      "MAE for fold 6: 84924.07845612156\n",
      "Processing fold 7...\n",
      "Converged at epoch 1\n",
      "MAE for fold 7: 88271.47014217477\n",
      "Processing fold 8...\n",
      "Converged at epoch 1\n",
      "MAE for fold 8: 91278.17017873103\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 88563.40205838904\n",
      "Processing fold 10...\n",
      "Converged at epoch 6\n",
      "MAE for fold 10: 89960.62797520011\n",
      "Mean MAE: 95963.81845865205\n",
      "\n",
      "Training with alpha=0.6, lambda=0.3, epsilon=0.0009118819655545166, layer=5, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170267.55553773372\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 150591.2156627382\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 156179.5348825706\n",
      "Processing fold 4...\n",
      "Converged at epoch 84\n",
      "MAE for fold 4: 163469.0039259631\n",
      "Processing fold 5...\n",
      "Converged at epoch 1\n",
      "MAE for fold 5: 158482.48940533868\n",
      "Processing fold 6...\n",
      "Converged at epoch 1\n",
      "MAE for fold 6: 149515.54636911923\n",
      "Processing fold 7...\n",
      "Converged at epoch 1\n",
      "MAE for fold 7: 150107.81178644445\n",
      "Processing fold 8...\n",
      "Converged at epoch 1\n",
      "MAE for fold 8: 156106.23769504562\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 153206.9336669984\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 154966.09831557187\n",
      "Mean MAE: 156289.24272475237\n",
      "\n",
      "Training with alpha=0.6, lambda=0.3, epsilon=0.0009118819655545166, layer=5, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159769.36205072684\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 130470.49583125273\n",
      "Processing fold 3...\n",
      "Converged at epoch 777\n",
      "MAE for fold 3: 134566.60449818426\n",
      "Processing fold 4...\n",
      "Converged at epoch 1\n",
      "MAE for fold 4: 141878.93552487853\n",
      "Processing fold 5...\n",
      "Converged at epoch 59\n",
      "MAE for fold 5: 136946.4232446743\n",
      "Processing fold 6...\n",
      "Converged at epoch 1\n",
      "MAE for fold 6: 127861.03981020924\n",
      "Processing fold 7...\n",
      "Converged at epoch 68\n",
      "MAE for fold 7: 128708.65310221646\n",
      "Processing fold 8...\n",
      "Converged at epoch 607\n",
      "MAE for fold 8: 134165.25131547955\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 131266.18243847517\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 133025.5808889601\n",
      "Mean MAE: 135865.8528705057\n",
      "\n",
      "Training with alpha=0.6, lambda=0.3, epsilon=0.0009118819655545166, layer=5, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138886.90181672614\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 92181.64290438431\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 91696.58790713803\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 99983.68396957016\n",
      "Processing fold 5...\n",
      "Converged at epoch 764\n",
      "MAE for fold 5: 93887.02947802977\n",
      "Processing fold 6...\n",
      "Converged at epoch 1\n",
      "MAE for fold 6: 84924.08433900974\n",
      "Processing fold 7...\n",
      "Converged at epoch 1\n",
      "MAE for fold 7: 88271.47553434724\n",
      "Processing fold 8...\n",
      "Converged at epoch 1\n",
      "MAE for fold 8: 91278.17581257224\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 88563.40820198937\n",
      "Processing fold 10...\n",
      "Converged at epoch 8\n",
      "MAE for fold 10: 89960.62082871726\n",
      "Mean MAE: 95963.36107924843\n",
      "\n",
      "Training with alpha=0.6, lambda=0.3, epsilon=0.0009118819655545166, layer=10, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170270.11127569806\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 150592.41993387172\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 156179.60269329863\n",
      "Processing fold 4...\n",
      "Converged at epoch 84\n",
      "MAE for fold 4: 163469.05702629167\n",
      "Processing fold 5...\n",
      "Converged at epoch 1\n",
      "MAE for fold 5: 158482.54220101482\n",
      "Processing fold 6...\n",
      "Converged at epoch 1\n",
      "MAE for fold 6: 149515.59886189093\n",
      "Processing fold 7...\n",
      "Converged at epoch 1\n",
      "MAE for fold 7: 150107.8639780495\n",
      "Processing fold 8...\n",
      "Converged at epoch 1\n",
      "MAE for fold 8: 156106.28958721197\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 153206.98526144394\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 154966.14961400474\n",
      "Mean MAE: 156289.66204327758\n",
      "\n",
      "Training with alpha=0.6, lambda=0.3, epsilon=0.0009118819655545166, layer=10, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159768.4820831464\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 130470.08688677644\n",
      "Processing fold 3...\n",
      "Converged at epoch 777\n",
      "MAE for fold 3: 134566.56027995117\n",
      "Processing fold 4...\n",
      "Converged at epoch 1\n",
      "MAE for fold 4: 141878.89156033864\n",
      "Processing fold 5...\n",
      "Converged at epoch 59\n",
      "MAE for fold 5: 136946.38675696362\n",
      "Processing fold 6...\n",
      "Converged at epoch 1\n",
      "MAE for fold 6: 127861.00302797316\n",
      "Processing fold 7...\n",
      "Converged at epoch 68\n",
      "MAE for fold 7: 128708.62376876063\n",
      "Processing fold 8...\n",
      "Converged at epoch 607\n",
      "MAE for fold 8: 134165.24607010122\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 131266.17722319122\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 133025.57570359774\n",
      "Mean MAE: 135865.70333608\n",
      "\n",
      "Training with alpha=0.6, lambda=0.3, epsilon=0.0009118819655545166, layer=10, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138887.18171430024\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 92181.76397808379\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 91696.59482791423\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 99983.68432437039\n",
      "Processing fold 5...\n",
      "Converged at epoch 764\n",
      "MAE for fold 5: 93887.02952052977\n",
      "Processing fold 6...\n",
      "Converged at epoch 1\n",
      "MAE for fold 6: 84924.08437998542\n",
      "Processing fold 7...\n",
      "Converged at epoch 1\n",
      "MAE for fold 7: 88271.475571905\n",
      "Processing fold 8...\n",
      "Converged at epoch 1\n",
      "MAE for fold 8: 91278.17585181327\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 88563.40824478102\n",
      "Processing fold 10...\n",
      "Converged at epoch 8\n",
      "MAE for fold 10: 89960.62087164153\n",
      "Mean MAE: 95963.40192853249\n",
      "\n",
      "Training with alpha=0.6, lambda=0.3, epsilon=0.0024787521766663594, layer=1, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170276.4202064416\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 150595.41739906822\n",
      "Processing fold 3...\n",
      "Converged at epoch 911\n",
      "MAE for fold 3: 156213.2731991751\n",
      "Processing fold 4...\n",
      "Converged at epoch 1\n",
      "MAE for fold 4: 163527.05766284594\n",
      "Processing fold 5...\n",
      "Converged at epoch 1\n",
      "MAE for fold 5: 158540.2100706666\n",
      "Processing fold 6...\n",
      "Converged at epoch 1\n",
      "MAE for fold 6: 149572.9358738448\n",
      "Processing fold 7...\n",
      "Converged at epoch 1\n",
      "MAE for fold 7: 150164.87203051054\n",
      "Processing fold 8...\n",
      "Converged at epoch 1\n",
      "MAE for fold 8: 156162.9705675291\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 153263.3410461347\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 155022.1820687999\n",
      "Mean MAE: 156333.86801250165\n",
      "\n",
      "Training with alpha=0.6, lambda=0.3, epsilon=0.0024787521766663594, layer=1, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159780.1214381944\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 130475.52286696306\n",
      "Processing fold 3...\n",
      "Converged at epoch 735\n",
      "MAE for fold 3: 134618.99166429543\n",
      "Processing fold 4...\n",
      "Converged at epoch 1\n",
      "MAE for fold 4: 141931.02213027974\n",
      "Processing fold 5...\n",
      "Converged at epoch 45\n",
      "MAE for fold 5: 137005.0996003341\n",
      "Processing fold 6...\n",
      "Converged at epoch 1\n",
      "MAE for fold 6: 127920.18979598561\n",
      "Processing fold 7...\n",
      "Converged at epoch 50\n",
      "MAE for fold 7: 128772.54472732148\n",
      "Processing fold 8...\n",
      "Converged at epoch 1\n",
      "MAE for fold 8: 134456.12170643674\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 131555.3840195524\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 133313.12323458542\n",
      "Mean MAE: 135982.81211839482\n",
      "\n",
      "Training with alpha=0.6, lambda=0.3, epsilon=0.0024787521766663594, layer=1, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138901.21229122134\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 92280.91053579704\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 92220.333952212\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 100077.53131352192\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 93800.20273806667\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 84961.50166121603\n",
      "Processing fold 7...\n",
      "Converged at epoch 858\n",
      "MAE for fold 7: 87366.29899625017\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 91143.60328702831\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 88543.82771088407\n",
      "Processing fold 10...\n",
      "Converged at epoch 571\n",
      "MAE for fold 10: 89739.05312790707\n",
      "Mean MAE: 95903.44756141046\n",
      "\n",
      "Training with alpha=0.6, lambda=0.3, epsilon=0.0024787521766663594, layer=3, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170269.76908526223\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 150592.25807979357\n",
      "Processing fold 3...\n",
      "Converged at epoch 910\n",
      "MAE for fold 3: 156213.47493424843\n",
      "Processing fold 4...\n",
      "Converged at epoch 1\n",
      "MAE for fold 4: 163527.25824049397\n",
      "Processing fold 5...\n",
      "Converged at epoch 1\n",
      "MAE for fold 5: 158540.40949755095\n",
      "Processing fold 6...\n",
      "Converged at epoch 1\n",
      "MAE for fold 6: 149573.1341565457\n",
      "Processing fold 7...\n",
      "Converged at epoch 1\n",
      "MAE for fold 7: 150165.06917561643\n",
      "Processing fold 8...\n",
      "Converged at epoch 1\n",
      "MAE for fold 8: 156163.16658155608\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 153263.5359355649\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 155022.37584009845\n",
      "Mean MAE: 156333.04515267306\n",
      "\n",
      "Training with alpha=0.6, lambda=0.3, epsilon=0.0024787521766663594, layer=3, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159769.32359621872\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 130470.47780589102\n",
      "Processing fold 3...\n",
      "Converged at epoch 734\n",
      "MAE for fold 3: 134619.6866526078\n",
      "Processing fold 4...\n",
      "Converged at epoch 1\n",
      "MAE for fold 4: 141931.71313120352\n",
      "Processing fold 5...\n",
      "Converged at epoch 46\n",
      "MAE for fold 5: 137004.57076980115\n",
      "Processing fold 6...\n",
      "Converged at epoch 1\n",
      "MAE for fold 6: 127919.65669674856\n",
      "Processing fold 7...\n",
      "Converged at epoch 50\n",
      "MAE for fold 7: 128772.09699050829\n",
      "Processing fold 8...\n",
      "Converged at epoch 1\n",
      "MAE for fold 8: 134455.66399848135\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 131554.92893758928\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 133312.67076357853\n",
      "Mean MAE: 135981.0789342628\n",
      "\n",
      "Training with alpha=0.6, lambda=0.3, epsilon=0.0024787521766663594, layer=3, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138889.70235221597\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 92182.85134952025\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 91696.65698389441\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 99983.68751085669\n",
      "Processing fold 5...\n",
      "Converged at epoch 416\n",
      "MAE for fold 5: 93890.97232367452\n",
      "Processing fold 6...\n",
      "Converged at epoch 1\n",
      "MAE for fold 6: 84927.88576869923\n",
      "Processing fold 7...\n",
      "Converged at epoch 1\n",
      "MAE for fold 7: 88274.95987131115\n",
      "Processing fold 8...\n",
      "Converged at epoch 1\n",
      "MAE for fold 8: 91281.81631206027\n",
      "Processing fold 9...\n",
      "Converged at epoch 2\n",
      "MAE for fold 9: 88567.3600722674\n",
      "Processing fold 10...\n",
      "Converged at epoch 7\n",
      "MAE for fold 10: 89964.60303396439\n",
      "Mean MAE: 95966.04955784643\n",
      "\n",
      "Training with alpha=0.6, lambda=0.3, epsilon=0.0024787521766663594, layer=5, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170272.79193375877\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 150593.68164419706\n",
      "Processing fold 3...\n",
      "Converged at epoch 910\n",
      "MAE for fold 3: 156213.57848426042\n",
      "Processing fold 4...\n",
      "Converged at epoch 1\n",
      "MAE for fold 4: 163527.3611964088\n",
      "Processing fold 5...\n",
      "Converged at epoch 1\n",
      "MAE for fold 5: 158540.51186277706\n",
      "Processing fold 6...\n",
      "Converged at epoch 1\n",
      "MAE for fold 6: 149573.2359344721\n",
      "Processing fold 7...\n",
      "Converged at epoch 1\n",
      "MAE for fold 7: 150165.17036961258\n",
      "Processing fold 8...\n",
      "Converged at epoch 1\n",
      "MAE for fold 8: 156163.2671949723\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 153263.63597173194\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 155022.47530232833\n",
      "Mean MAE: 156333.57098945195\n",
      "\n",
      "Training with alpha=0.6, lambda=0.3, epsilon=0.0024787521766663594, layer=5, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159771.8380748007\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 130471.64564137073\n",
      "Processing fold 3...\n",
      "Converged at epoch 734\n",
      "MAE for fold 3: 134619.829556486\n",
      "Processing fold 4...\n",
      "Converged at epoch 1\n",
      "MAE for fold 4: 141931.85521519964\n",
      "Processing fold 5...\n",
      "Converged at epoch 46\n",
      "MAE for fold 5: 137004.69318399698\n",
      "Processing fold 6...\n",
      "Converged at epoch 1\n",
      "MAE for fold 6: 127919.78009906031\n",
      "Processing fold 7...\n",
      "Converged at epoch 50\n",
      "MAE for fold 7: 128772.20063305237\n",
      "Processing fold 8...\n",
      "Converged at epoch 1\n",
      "MAE for fold 8: 134455.76994915557\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 131555.03428039295\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 133312.77550199928\n",
      "Mean MAE: 135981.54221355147\n",
      "\n",
      "Training with alpha=0.6, lambda=0.3, epsilon=0.0024787521766663594, layer=5, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138889.21444213297\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 92182.64086931534\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 91696.64495249164\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 99983.68689405543\n",
      "Processing fold 5...\n",
      "Converged at epoch 416\n",
      "MAE for fold 5: 93890.97212260393\n",
      "Processing fold 6...\n",
      "Converged at epoch 1\n",
      "MAE for fold 6: 84927.88557484029\n",
      "Processing fold 7...\n",
      "Converged at epoch 1\n",
      "MAE for fold 7: 88274.95969362276\n",
      "Processing fold 8...\n",
      "Converged at epoch 1\n",
      "MAE for fold 8: 91281.81612640822\n",
      "Processing fold 9...\n",
      "Converged at epoch 2\n",
      "MAE for fold 9: 88567.35987039856\n",
      "Processing fold 10...\n",
      "Converged at epoch 7\n",
      "MAE for fold 10: 89964.60283088655\n",
      "Mean MAE: 95965.97833767557\n",
      "\n",
      "Training with alpha=0.6, lambda=0.3, epsilon=0.0024787521766663594, layer=10, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170268.38260515846\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 150591.60493135647\n",
      "Processing fold 3...\n",
      "Converged at epoch 910\n",
      "MAE for fold 3: 156213.42742426\n",
      "Processing fold 4...\n",
      "Converged at epoch 1\n",
      "MAE for fold 4: 163527.2110030845\n",
      "Processing fold 5...\n",
      "Converged at epoch 1\n",
      "MAE for fold 5: 158540.36253115657\n",
      "Processing fold 6...\n",
      "Converged at epoch 1\n",
      "MAE for fold 6: 149573.08745961142\n",
      "Processing fold 7...\n",
      "Converged at epoch 1\n",
      "MAE for fold 7: 150165.02274659637\n",
      "Processing fold 8...\n",
      "Converged at epoch 1\n",
      "MAE for fold 8: 156163.12041891314\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 153263.4900377707\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 155022.33020563363\n",
      "Mean MAE: 156332.80393635412\n",
      "\n",
      "Training with alpha=0.6, lambda=0.3, epsilon=0.0024787521766663594, layer=10, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159768.14213552958\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 130469.92919209992\n",
      "Processing fold 3...\n",
      "Converged at epoch 734\n",
      "MAE for fold 3: 134619.61952068756\n",
      "Processing fold 4...\n",
      "Converged at epoch 1\n",
      "MAE for fold 4: 141931.64638443902\n",
      "Processing fold 5...\n",
      "Converged at epoch 46\n",
      "MAE for fold 5: 137004.5132633141\n",
      "Processing fold 6...\n",
      "Converged at epoch 1\n",
      "MAE for fold 6: 127919.5987260744\n",
      "Processing fold 7...\n",
      "Converged at epoch 50\n",
      "MAE for fold 7: 128772.0483023755\n",
      "Processing fold 8...\n",
      "Converged at epoch 1\n",
      "MAE for fold 8: 134455.61422605885\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 131554.87945072594\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 133312.6215606361\n",
      "Mean MAE: 135980.86127619407\n",
      "\n",
      "Training with alpha=0.6, lambda=0.3, epsilon=0.0024787521766663594, layer=10, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138890.9813857812\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 92183.40336031176\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 91696.68853775943\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 99983.6891284963\n",
      "Processing fold 5...\n",
      "Converged at epoch 416\n",
      "MAE for fold 5: 93890.97285100805\n",
      "Processing fold 6...\n",
      "Converged at epoch 1\n",
      "MAE for fold 6: 84927.88627711919\n",
      "Processing fold 7...\n",
      "Converged at epoch 1\n",
      "MAE for fold 7: 88274.96033732164\n",
      "Processing fold 8...\n",
      "Converged at epoch 1\n",
      "MAE for fold 8: 91281.81679895669\n",
      "Processing fold 9...\n",
      "Converged at epoch 2\n",
      "MAE for fold 9: 88567.36060169336\n",
      "Processing fold 10...\n",
      "Converged at epoch 7\n",
      "MAE for fold 10: 89964.60356656197\n",
      "Mean MAE: 95966.23628450095\n",
      "\n",
      "Training with alpha=0.6, lambda=0.3, epsilon=0.006737946999085469, layer=1, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170268.76750145646\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 150591.78776533264\n",
      "Processing fold 3...\n",
      "Converged at epoch 736\n",
      "MAE for fold 3: 156310.8633358936\n",
      "Processing fold 4...\n",
      "Converged at epoch 1\n",
      "MAE for fold 4: 163624.0878959411\n",
      "Processing fold 5...\n",
      "Converged at epoch 1\n",
      "MAE for fold 5: 158636.68361247235\n",
      "Processing fold 6...\n",
      "Converged at epoch 1\n",
      "MAE for fold 6: 149668.85591826434\n",
      "Processing fold 7...\n",
      "Converged at epoch 1\n",
      "MAE for fold 7: 150260.24175312291\n",
      "Processing fold 8...\n",
      "Converged at epoch 1\n",
      "MAE for fold 8: 156257.79312569415\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 153357.61957909734\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 155115.9196977947\n",
      "Mean MAE: 156409.26201850697\n",
      "\n",
      "Training with alpha=0.6, lambda=0.3, epsilon=0.006737946999085469, layer=1, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 160357.48343964355\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 130815.5696156749\n",
      "Processing fold 3...\n",
      "Converged at epoch 701\n",
      "MAE for fold 3: 134711.55310006547\n",
      "Processing fold 4...\n",
      "Converged at epoch 1\n",
      "MAE for fold 4: 142023.0525135789\n",
      "Processing fold 5...\n",
      "Converged at epoch 30\n",
      "MAE for fold 5: 137105.3810507701\n",
      "Processing fold 6...\n",
      "Converged at epoch 1\n",
      "MAE for fold 6: 128021.28070895854\n",
      "Processing fold 7...\n",
      "Converged at epoch 32\n",
      "MAE for fold 7: 128879.56976798855\n",
      "Processing fold 8...\n",
      "Converged at epoch 1\n",
      "MAE for fold 8: 134565.53020576475\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 131664.1648097979\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 133421.2799171023\n",
      "Mean MAE: 136156.4865129345\n",
      "\n",
      "Training with alpha=0.6, lambda=0.3, epsilon=0.006737946999085469, layer=1, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138944.06110370433\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 92172.3813731797\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 92243.92477446115\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 100125.40619399621\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 93483.00329286962\n",
      "Processing fold 6...\n",
      "Converged at epoch 644\n",
      "MAE for fold 6: 84905.10965465775\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 87645.5157376576\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 91167.44863812537\n",
      "Processing fold 9...\n",
      "Converged at epoch 842\n",
      "MAE for fold 9: 88433.8016193986\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 89805.30253653514\n",
      "Mean MAE: 95892.59549245852\n",
      "\n",
      "Training with alpha=0.6, lambda=0.3, epsilon=0.006737946999085469, layer=3, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170269.57887966334\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 150592.16797228373\n",
      "Processing fold 3...\n",
      "Converged at epoch 736\n",
      "MAE for fold 3: 156310.90895990186\n",
      "Processing fold 4...\n",
      "Converged at epoch 1\n",
      "MAE for fold 4: 163624.13325817994\n",
      "Processing fold 5...\n",
      "Converged at epoch 1\n",
      "MAE for fold 5: 158636.7287144642\n",
      "Processing fold 6...\n",
      "Converged at epoch 1\n",
      "MAE for fold 6: 149668.90076148056\n",
      "Processing fold 7...\n",
      "Converged at epoch 1\n",
      "MAE for fold 7: 150260.28633907207\n",
      "Processing fold 8...\n",
      "Converged at epoch 1\n",
      "MAE for fold 8: 156257.83745584157\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 153357.6636549036\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 155115.96352073175\n",
      "Mean MAE: 156409.41695165227\n",
      "\n",
      "Training with alpha=0.6, lambda=0.3, epsilon=0.006737946999085469, layer=3, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159768.3407198331\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 130470.021196193\n",
      "Processing fold 3...\n",
      "Converged at epoch 660\n",
      "MAE for fold 3: 134727.8511235745\n",
      "Processing fold 4...\n",
      "Converged at epoch 1\n",
      "MAE for fold 4: 142039.25703044827\n",
      "Processing fold 5...\n",
      "Converged at epoch 31\n",
      "MAE for fold 5: 137118.5456577289\n",
      "Processing fold 6...\n",
      "Converged at epoch 1\n",
      "MAE for fold 6: 128034.55157936676\n",
      "Processing fold 7...\n",
      "Converged at epoch 32\n",
      "MAE for fold 7: 128891.30803121443\n",
      "Processing fold 8...\n",
      "Converged at epoch 1\n",
      "MAE for fold 8: 134577.52988132203\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 131676.0956396354\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 133433.14229623805\n",
      "Mean MAE: 136073.66431555545\n",
      "\n",
      "Training with alpha=0.6, lambda=0.3, epsilon=0.006737946999085469, layer=3, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138888.8385243134\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 92182.47863722409\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 91696.63567903255\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 99983.68641864244\n",
      "Processing fold 5...\n",
      "Converged at epoch 68\n",
      "MAE for fold 5: 93901.70045368047\n",
      "Processing fold 6...\n",
      "Converged at epoch 1\n",
      "MAE for fold 6: 84938.22911855154\n",
      "Processing fold 7...\n",
      "Converged at epoch 1\n",
      "MAE for fold 7: 88284.44044024545\n",
      "Processing fold 8...\n",
      "Converged at epoch 1\n",
      "MAE for fold 8: 91291.7217852419\n",
      "Processing fold 9...\n",
      "Converged at epoch 2\n",
      "MAE for fold 9: 88578.13077828356\n",
      "Processing fold 10...\n",
      "Converged at epoch 7\n",
      "MAE for fold 10: 89975.43825792414\n",
      "Mean MAE: 95972.13000931396\n",
      "\n",
      "Training with alpha=0.6, lambda=0.3, epsilon=0.006737946999085469, layer=5, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170269.37278991015\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 150592.07100957684\n",
      "Processing fold 3...\n",
      "Converged at epoch 736\n",
      "MAE for fold 3: 156310.8973245945\n",
      "Processing fold 4...\n",
      "Converged at epoch 1\n",
      "MAE for fold 4: 163624.12168962773\n",
      "Processing fold 5...\n",
      "Converged at epoch 1\n",
      "MAE for fold 5: 158636.7172122843\n",
      "Processing fold 6...\n",
      "Converged at epoch 1\n",
      "MAE for fold 6: 149668.88932529205\n",
      "Processing fold 7...\n",
      "Converged at epoch 1\n",
      "MAE for fold 7: 150260.27496849632\n",
      "Processing fold 8...\n",
      "Converged at epoch 1\n",
      "MAE for fold 8: 156257.82615050225\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 153357.65241442632\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 155115.95234474447\n",
      "Mean MAE: 156409.3775229455\n",
      "\n",
      "Training with alpha=0.6, lambda=0.3, epsilon=0.006737946999085469, layer=5, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159764.6676934326\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 130468.31639897915\n",
      "Processing fold 3...\n",
      "Converged at epoch 660\n",
      "MAE for fold 3: 134727.59302084908\n",
      "Processing fold 4...\n",
      "Converged at epoch 1\n",
      "MAE for fold 4: 142039.0004085349\n",
      "Processing fold 5...\n",
      "Converged at epoch 31\n",
      "MAE for fold 5: 137118.31481205125\n",
      "Processing fold 6...\n",
      "Converged at epoch 1\n",
      "MAE for fold 6: 128034.3188703242\n",
      "Processing fold 7...\n",
      "Converged at epoch 32\n",
      "MAE for fold 7: 128891.10219693939\n",
      "Processing fold 8...\n",
      "Converged at epoch 1\n",
      "MAE for fold 8: 134577.31946309656\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 131675.88642864177\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 133432.93428555017\n",
      "Mean MAE: 136072.9453578399\n",
      "\n",
      "Training with alpha=0.6, lambda=0.3, epsilon=0.006737946999085469, layer=5, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138889.2799419501\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 92182.66938333887\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 91696.64658240131\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 99983.68697761428\n",
      "Processing fold 5...\n",
      "Converged at epoch 68\n",
      "MAE for fold 5: 93901.70094957978\n",
      "Processing fold 6...\n",
      "Converged at epoch 1\n",
      "MAE for fold 6: 84938.22959666462\n",
      "Processing fold 7...\n",
      "Converged at epoch 1\n",
      "MAE for fold 7: 88284.44087847711\n",
      "Processing fold 8...\n",
      "Converged at epoch 1\n",
      "MAE for fold 8: 91291.72224311442\n",
      "Processing fold 9...\n",
      "Converged at epoch 2\n",
      "MAE for fold 9: 88578.13127615064\n",
      "Processing fold 10...\n",
      "Converged at epoch 7\n",
      "MAE for fold 10: 89975.43875877376\n",
      "Mean MAE: 95972.19465880647\n",
      "\n",
      "Training with alpha=0.6, lambda=0.3, epsilon=0.006737946999085469, layer=10, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170272.6475253906\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 150593.61311667\n",
      "Processing fold 3...\n",
      "Converged at epoch 736\n",
      "MAE for fold 3: 156311.08237398922\n",
      "Processing fold 4...\n",
      "Converged at epoch 1\n",
      "MAE for fold 4: 163624.3056773391\n",
      "Processing fold 5...\n",
      "Converged at epoch 1\n",
      "MAE for fold 5: 158636.90014440342\n",
      "Processing fold 6...\n",
      "Converged at epoch 1\n",
      "MAE for fold 6: 149669.0712078752\n",
      "Processing fold 7...\n",
      "Converged at epoch 1\n",
      "MAE for fold 7: 150260.4558075651\n",
      "Processing fold 8...\n",
      "Converged at epoch 1\n",
      "MAE for fold 8: 156258.00595204352\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 153357.83118439268\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 155116.1300890544\n",
      "Mean MAE: 156410.0043078723\n",
      "\n",
      "Training with alpha=0.6, lambda=0.3, epsilon=0.006737946999085469, layer=10, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159768.88803392556\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 130470.27536487089\n",
      "Processing fold 3...\n",
      "Converged at epoch 660\n",
      "MAE for fold 3: 134727.88960417992\n",
      "Processing fold 4...\n",
      "Converged at epoch 1\n",
      "MAE for fold 4: 142039.295290279\n",
      "Processing fold 5...\n",
      "Converged at epoch 31\n",
      "MAE for fold 5: 137118.58007457366\n",
      "Processing fold 6...\n",
      "Converged at epoch 1\n",
      "MAE for fold 6: 128034.58627402104\n",
      "Processing fold 7...\n",
      "Converged at epoch 32\n",
      "MAE for fold 7: 128891.33871910236\n",
      "Processing fold 8...\n",
      "Converged at epoch 1\n",
      "MAE for fold 8: 134577.56125263238\n",
      "Processing fold 9...\n",
      "Converged at epoch 1\n",
      "MAE for fold 9: 131676.12683095917\n",
      "Processing fold 10...\n",
      "Converged at epoch 1\n",
      "MAE for fold 10: 133433.17330860806\n",
      "Mean MAE: 136073.7714753152\n",
      "\n",
      "Training with alpha=0.6, lambda=0.3, epsilon=0.006737946999085469, layer=10, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138888.51279064495\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 92182.33819126953\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 91696.62765090568\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 99983.68600707267\n",
      "Processing fold 5...\n",
      "Converged at epoch 68\n",
      "MAE for fold 5: 93901.70008855048\n",
      "Processing fold 6...\n",
      "Converged at epoch 1\n",
      "MAE for fold 6: 84938.22876651738\n",
      "Processing fold 7...\n",
      "Converged at epoch 1\n",
      "MAE for fold 7: 88284.44011757588\n",
      "Processing fold 8...\n",
      "Converged at epoch 1\n",
      "MAE for fold 8: 91291.72144811085\n",
      "Processing fold 9...\n",
      "Converged at epoch 2\n",
      "MAE for fold 9: 88578.13041170429\n",
      "Processing fold 10...\n",
      "Converged at epoch 7\n",
      "MAE for fold 10: 89975.43788914925\n",
      "Mean MAE: 95972.08233615011\n",
      "\n",
      "Training with alpha=0.7, lambda=0, epsilon=0.0009118819655545166, layer=1, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170269.03556984637\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149609.96022738918\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 144543.17255611045\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 139257.81639168118\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 121996.4850730784\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 100105.39858337032\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 91432.47325729518\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 83817.72587697058\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 70650.4682910478\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 62668.39738303711\n",
      "Mean MAE: 113435.09332098265\n",
      "\n",
      "Training with alpha=0.7, lambda=0, epsilon=0.0009118819655545166, layer=1, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 161877.91850882978\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 132846.12304043607\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 119360.39016364841\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 106946.8169311334\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 82536.14686036062\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 58737.5702650941\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 60481.85879361553\n",
      "Processing fold 8...\n",
      "Converged at epoch 747\n",
      "MAE for fold 8: 54395.84625716925\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 41569.72280889985\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 30509.409649969763\n",
      "Mean MAE: 84926.18032791567\n",
      "\n",
      "Training with alpha=0.7, lambda=0, epsilon=0.0009118819655545166, layer=1, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 139645.3659450268\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89876.110591196\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 60150.41771103934\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 60407.156762580234\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 38878.27184469685\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 26439.326601562974\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 23667.5719035745\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 18946.534949832174\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 18325.220674463217\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 19845.939604300474\n",
      "Mean MAE: 49618.19165882726\n",
      "\n",
      "Training with alpha=0.7, lambda=0, epsilon=0.0009118819655545166, layer=3, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170271.22498382666\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149612.1496413692\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 144545.36197009042\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 139260.00580566097\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 121998.64449508596\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 100107.58799735006\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 91434.33275957944\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 83819.49540333782\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 70652.02787360875\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 62669.712731941705\n",
      "Mean MAE: 113437.05436618507\n",
      "\n",
      "Training with alpha=0.7, lambda=0, epsilon=0.0009118819655545166, layer=3, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159770.75190448723\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 128696.58885533243\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 113139.62310182478\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 99614.78161568801\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 74434.04020051318\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 54099.80067387481\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 60493.97509420411\n",
      "Processing fold 8...\n",
      "Converged at epoch 42\n",
      "MAE for fold 8: 54395.733018575935\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 54834.462410790744\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 52561.821385832685\n",
      "Mean MAE: 85204.15782611238\n",
      "\n",
      "Training with alpha=0.7, lambda=0, epsilon=0.0009118819655545166, layer=3, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138890.51498864056\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89226.10004541864\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 59783.476273905515\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 60432.983337784826\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 53736.33794700324\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 52973.98703088653\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 64116.3335706338\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 55426.12257613416\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 55644.338569734384\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 52703.360932298645\n",
      "Mean MAE: 68293.35552724401\n",
      "\n",
      "Training with alpha=0.7, lambda=0, epsilon=0.0009118819655545166, layer=5, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170270.39584460625\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149611.32050214882\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 144544.53283087\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 139259.17666644056\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 121997.82671393699\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 100106.75885812961\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 91433.62855914567\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 83818.8252771186\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 70651.4372538901\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 62669.2129767952\n",
      "Mean MAE: 113436.3115483082\n",
      "\n",
      "Training with alpha=0.7, lambda=0, epsilon=0.0009118819655545166, layer=5, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159770.46430269565\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 128696.3051932914\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 113139.33943978371\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 99614.54129090329\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 74433.83533348353\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 54099.15321587424\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 60494.63554917042\n",
      "Processing fold 8...\n",
      "Converged at epoch 41\n",
      "MAE for fold 8: 54396.018629436665\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 54798.92253723522\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 52565.27089305016\n",
      "Mean MAE: 85200.84863849242\n",
      "\n",
      "Training with alpha=0.7, lambda=0, epsilon=0.0009118819655545166, layer=5, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138892.3950420406\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89227.71898029087\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 59784.390188752724\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 60433.339164346326\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 53739.13114721548\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 52926.5210854116\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 64119.47700243946\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 55421.94791782648\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 55667.12033603364\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 52695.53457916107\n",
      "Mean MAE: 68290.75754435183\n",
      "\n",
      "Training with alpha=0.7, lambda=0, epsilon=0.0009118819655545166, layer=10, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170270.73475177382\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149611.65940931637\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 144544.87173803756\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 139259.5155736081\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 121998.16097854062\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 100107.09776529718\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 91433.9163981099\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 83819.09918839099\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 70651.67866721493\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 62669.41724960848\n",
      "Mean MAE: 113436.6151719898\n",
      "\n",
      "Training with alpha=0.7, lambda=0, epsilon=0.0009118819655545166, layer=10, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159769.30389404646\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 128695.16068065105\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 113138.19492714344\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 99613.57163436081\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 74433.0087410211\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 54098.851191705275\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 60495.59065684912\n",
      "Processing fold 8...\n",
      "Converged at epoch 41\n",
      "MAE for fold 8: 54395.59340156548\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 54810.46400226316\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 52569.22554558394\n",
      "Mean MAE: 85201.89646751899\n",
      "\n",
      "Training with alpha=0.7, lambda=0, epsilon=0.0009118819655545166, layer=10, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138891.14871633885\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89226.64575538106\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 59783.78433598106\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 60435.019363567204\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 53739.217697611435\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 52994.40688846611\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 64120.28174935098\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 55425.566199276625\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 55705.93890721905\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 52676.876136705876\n",
      "Mean MAE: 68299.88857498982\n",
      "\n",
      "Training with alpha=0.7, lambda=0, epsilon=0.0024787521766663594, layer=1, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170280.92636683214\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149621.85102437495\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 144555.06335309625\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 139269.70718866697\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 122008.21298243421\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 100117.28938035606\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 91442.57229035156\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 83827.33624713698\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 70658.93844780466\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 62675.56014087669\n",
      "Mean MAE: 113445.74574219307\n",
      "\n",
      "Training with alpha=0.7, lambda=0, epsilon=0.0024787521766663594, layer=1, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159799.4412152003\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 128724.88516178937\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 113167.9194082818\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 99638.754875325\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 74454.47642184334\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 54106.69515200592\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 60493.12269454664\n",
      "Processing fold 8...\n",
      "Converged at epoch 42\n",
      "MAE for fold 8: 54395.97900820415\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 54824.707365830225\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 30951.86987524217\n",
      "Mean MAE: 83055.78511782688\n",
      "\n",
      "Training with alpha=0.7, lambda=0, epsilon=0.0024787521766663594, layer=1, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138899.03935920188\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89233.44047562414\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 59787.62006515058\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 60433.20017259969\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 44822.65622917133\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 27061.40720935761\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 24586.23538872407\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 19675.45683981369\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 19421.037184601286\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 19978.230532494606\n",
      "Mean MAE: 50389.83234567389\n",
      "\n",
      "Training with alpha=0.7, lambda=0, epsilon=0.0024787521766663594, layer=3, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170270.27218758993\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149611.1968451325\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 144544.4091738537\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 139259.05300942424\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 121997.70475085243\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 100106.6352011133\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 91433.52353537838\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 83818.72533514649\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 70651.34916944012\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 62669.13844379905\n",
      "Mean MAE: 113436.20076517302\n",
      "\n",
      "Training with alpha=0.7, lambda=0, epsilon=0.0024787521766663594, layer=3, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159768.96266142445\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 128694.8241224485\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 113137.85836894086\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 99613.28649477249\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 74432.76567120811\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 54098.76237773514\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 60494.779542169046\n",
      "Processing fold 8...\n",
      "Converged at epoch 41\n",
      "MAE for fold 8: 54395.69525183277\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 54815.66675506558\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 52578.02584199794\n",
      "Mean MAE: 85203.06270875948\n",
      "\n",
      "Training with alpha=0.7, lambda=0, epsilon=0.0024787521766663594, layer=3, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138886.99686454114\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89223.07054966634\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 59781.76607469048\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 60423.513035699\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 53737.12810419357\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 52967.94413336106\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 64120.284356585486\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 55398.182114056006\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 55688.28331818693\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 52672.22885513094\n",
      "Mean MAE: 68289.9397406111\n",
      "\n",
      "Training with alpha=0.7, lambda=0, epsilon=0.0024787521766663594, layer=5, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170267.51906603397\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149608.44372357652\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 144541.6560522977\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 139256.29988786826\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 121994.98934329036\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 100103.88207955734\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 91431.18526775549\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 83816.50020950541\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 70649.38804175642\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 62667.50409996928\n",
      "Mean MAE: 113433.73677716106\n",
      "\n",
      "Training with alpha=0.7, lambda=0, epsilon=0.0024787521766663594, layer=5, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159768.24653387535\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 128694.11780486582\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 113137.1520513582\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 99612.68808682053\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 74432.25555295398\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 54098.575988373064\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 60495.692047550474\n",
      "Processing fold 8...\n",
      "Converged at epoch 41\n",
      "MAE for fold 8: 54396.258751693094\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 54798.92667517969\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 52557.589612670745\n",
      "Mean MAE: 85199.15031053408\n",
      "\n",
      "Training with alpha=0.7, lambda=0, epsilon=0.0024787521766663594, layer=5, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138891.32874434022\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89226.80077949331\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 59783.871849592826\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 60432.01758118964\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 53741.21889429704\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 52993.02609184999\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 64140.83849661484\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 55430.32436595772\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 55670.02486414215\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 52693.697587378876\n",
      "Mean MAE: 68300.31492548567\n",
      "\n",
      "Training with alpha=0.7, lambda=0, epsilon=0.0024787521766663594, layer=10, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170267.3691906213\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149608.29384816386\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 144541.50617688507\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 139256.1500124556\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 121994.84152096556\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 100103.73220414466\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 91431.05797630914\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 83816.37907732256\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 70649.28128118852\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 62667.41581719198\n",
      "Mean MAE: 113433.60271052484\n",
      "\n",
      "Training with alpha=0.7, lambda=0, epsilon=0.0024787521766663594, layer=10, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159769.91605822253\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 128695.76445901647\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 113138.79870550887\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 99614.0831688093\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 74433.4448031739\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 54099.01052210726\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 60493.844284941835\n",
      "Processing fold 8...\n",
      "Converged at epoch 42\n",
      "MAE for fold 8: 54395.80776672582\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 54795.72007361937\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 52571.916799872095\n",
      "Mean MAE: 85200.83066419975\n",
      "\n",
      "Training with alpha=0.7, lambda=0, epsilon=0.0024787521766663594, layer=10, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138890.11184039927\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89225.75288998862\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 59783.28029906599\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 60438.5290225806\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 53740.440387816525\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 52991.048265930105\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 64118.51189294682\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 55413.30291722345\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 55639.04974474758\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 52690.541273387935\n",
      "Mean MAE: 68293.05685340869\n",
      "\n",
      "Training with alpha=0.7, lambda=0, epsilon=0.006737946999085469, layer=1, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170381.80608272465\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149722.7307402679\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 144655.94306898917\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 139370.58690455992\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 122107.7107844108\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 100218.16909624901\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 91528.25095316477\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 83908.86916819966\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 70730.79797145312\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 62736.36435319463\n",
      "Mean MAE: 113536.12291232136\n",
      "\n",
      "Training with alpha=0.7, lambda=0, epsilon=0.006737946999085469, layer=1, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159848.644621692\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 128773.41454901424\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 113216.44879550672\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 99679.87005061268\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 74489.52542372799\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 54119.50151807916\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 60486.29497063642\n",
      "Processing fold 8...\n",
      "Converged at epoch 46\n",
      "MAE for fold 8: 54395.66138664208\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 36071.39363455886\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 30659.253966897126\n",
      "Mean MAE: 81174.00089173672\n",
      "\n",
      "Training with alpha=0.7, lambda=0, epsilon=0.006737946999085469, layer=1, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 139267.88696557662\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89551.05924778109\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 59966.92098491691\n",
      "Processing fold 4...\n",
      "Converged at epoch 708\n",
      "MAE for fold 4: 60423.112013965256\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 47425.73171545165\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 25826.02319757238\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 23920.996511528876\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 20383.527565909142\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 17251.778157356315\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 18551.158766220935\n",
      "Mean MAE: 50256.81951262792\n",
      "\n",
      "Training with alpha=0.7, lambda=0, epsilon=0.006737946999085469, layer=3, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170265.03455406474\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149605.9592116072\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 144539.17154032845\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 139253.815375899\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 121992.53886573165\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 100101.39756758806\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 91429.07513430213\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 83814.4921792837\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 70647.6182524085\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 62666.040620316206\n",
      "Mean MAE: 113431.51433015296\n",
      "\n",
      "Training with alpha=0.7, lambda=0, epsilon=0.006737946999085469, layer=3, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159770.60978678014\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 128696.44868444325\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 113139.48293093558\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 99614.66285979582\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 74433.9389659821\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 54099.19108159487\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 60495.88735206645\n",
      "Processing fold 8...\n",
      "Converged at epoch 41\n",
      "MAE for fold 8: 54395.90605322212\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 54812.0558715052\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 52593.91503458582\n",
      "Mean MAE: 85205.20986209114\n",
      "\n",
      "Training with alpha=0.7, lambda=0, epsilon=0.006737946999085469, layer=3, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138890.14201441128\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89225.77887316565\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 59783.29496698852\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 60434.384880493155\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 53737.87392159044\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 52993.405186132855\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 64157.64775802381\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 55427.984840895\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 55673.23640687852\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 52667.13875436367\n",
      "Mean MAE: 68299.0887602943\n",
      "\n",
      "Training with alpha=0.7, lambda=0, epsilon=0.006737946999085469, layer=5, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170268.277738605\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149609.20239614756\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 144542.41472486872\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 139257.05856043927\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 121995.73762308646\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 100104.64075212838\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 91431.82961980213\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 83817.11338322719\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 70649.92846605359\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 62667.95098929194\n",
      "Mean MAE: 113434.41542536502\n",
      "\n",
      "Training with alpha=0.7, lambda=0, epsilon=0.006737946999085469, layer=5, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159770.91991716812\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 128696.75456646968\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 113139.78881296204\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 99614.92200984602\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 74434.159880779\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 54099.27180046296\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 60494.38090120733\n",
      "Processing fold 8...\n",
      "Converged at epoch 42\n",
      "MAE for fold 8: 54396.344964476266\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 54821.102736604735\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 52571.28001336406\n",
      "Mean MAE: 85203.89256033403\n",
      "\n",
      "Training with alpha=0.7, lambda=0, epsilon=0.006737946999085469, layer=5, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138892.02814977488\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89227.4030452843\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 59784.21183834584\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 60431.74858834586\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 53738.16529855222\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 52975.23128859451\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 64150.852990936946\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 55406.55997380262\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 55669.0336834004\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 52680.18766491625\n",
      "Mean MAE: 68295.54225219539\n",
      "\n",
      "Training with alpha=0.7, lambda=0, epsilon=0.006737946999085469, layer=10, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170267.7096873752\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149608.6343449177\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 144541.84667363894\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 139256.49050920946\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 121995.17735338032\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 100104.07270089856\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 91431.34716533296\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 83816.65427332911\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 70649.52382682145\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 62667.616383773006\n",
      "Mean MAE: 113433.90729186768\n",
      "\n",
      "Training with alpha=0.7, lambda=0, epsilon=0.006737946999085469, layer=10, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159770.6735798094\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 128696.51160359525\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 113139.54585008757\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 99614.71616629961\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 74433.9844075919\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 54099.20768525998\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 60493.77164588555\n",
      "Processing fold 8...\n",
      "Converged at epoch 42\n",
      "MAE for fold 8: 54395.72872681276\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 54804.253253523835\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 52562.741589533645\n",
      "Mean MAE: 85201.11345083996\n",
      "\n",
      "Training with alpha=0.7, lambda=0, epsilon=0.006737946999085469, layer=10, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138889.2082348871\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89224.97478524206\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 59782.84104638648\n",
      "Processing fold 4...\n",
      "Converged at epoch 699\n",
      "MAE for fold 4: 60423.126884206235\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 53721.35593521692\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 52944.44692245238\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 64127.268962690876\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 55418.790262122355\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 55684.2132992982\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 52666.769964672756\n",
      "Mean MAE: 68288.29962971754\n",
      "\n",
      "Training with alpha=0.7, lambda=0.1, epsilon=0.0009118819655545166, layer=1, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170271.47741903717\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149612.40207657896\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 144545.6144053009\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 139260.25824089607\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 121998.89347228066\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 102391.09017979959\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 101128.28404752212\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 104047.13791190993\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 101085.92949934692\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 102739.56329952394\n",
      "Mean MAE: 123708.06505521962\n",
      "\n",
      "Training with alpha=0.7, lambda=0.1, epsilon=0.0009118819655545166, layer=1, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159774.82791123434\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 128700.6090263684\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 113143.64327286374\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 99803.20527626232\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 73428.14031171665\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 52739.663697387055\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 53221.56935220444\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 52745.75302809212\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 50631.7535922134\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 50455.68149610798\n",
      "Mean MAE: 83464.48469644504\n",
      "\n",
      "Training with alpha=0.7, lambda=0.1, epsilon=0.0009118819655545166, layer=1, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138912.68468705143\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89245.19061904364\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 57821.66935076651\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 44740.83436412969\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 29332.627978376822\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 25093.416370281993\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 24698.484064089345\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 21300.422406170786\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 20202.13897264931\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 20379.201303538593\n",
      "Mean MAE: 47172.66701160981\n",
      "\n",
      "Training with alpha=0.7, lambda=0.1, epsilon=0.0009118819655545166, layer=3, npl=5\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 170269.31637687894\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 149610.2410344227\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 144543.45336314512\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 139258.09719871715\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 121996.76203344423\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 102390.02987371381\n",
      "Processing fold 7...\n",
      "Converged at epoch 735\n",
      "MAE for fold 7: 101761.48437503116\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 104249.59104518103\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 101175.81494876297\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 102762.5150142666\n",
      "Mean MAE: 123801.73052635638\n",
      "\n",
      "Training with alpha=0.7, lambda=0.1, epsilon=0.0009118819655545166, layer=3, npl=10\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 159768.32903267923\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 128694.19917355152\n",
      "Processing fold 3...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 3: 113137.23342004714\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 99612.75702418611\n",
      "Processing fold 5...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 5: 74432.31431923843\n",
      "Processing fold 6...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 6: 55276.926909618065\n",
      "Processing fold 7...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 7: 61485.68025949421\n",
      "Processing fold 8...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 8: 56838.58463954101\n",
      "Processing fold 9...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 9: 52362.36639462847\n",
      "Processing fold 10...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 10: 49585.206586741806\n",
      "Mean MAE: 85119.3597759726\n",
      "\n",
      "Training with alpha=0.7, lambda=0.1, epsilon=0.0009118819655545166, layer=3, npl=20\n",
      "\n",
      "Weights are valid.\n",
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "Processing fold 1...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 1: 138887.60521255076\n",
      "Processing fold 2...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 2: 89223.59440490308\n",
      "Processing fold 3...\n",
      "Converged at epoch 971\n",
      "MAE for fold 3: 60374.08919669244\n",
      "Processing fold 4...\n",
      "Training stopped after reaching max_epochs (1000).\n",
      "MAE for fold 4: 46969.92030553207\n",
      "Processing fold 5...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mneural_network\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgrid_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_fold_index\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/new/model.py:376\u001b[39m, in \u001b[36mMLPNeuralNetwork.grid_search\u001b[39m\u001b[34m(self, features, labels, params, k_fold_index)\u001b[39m\n\u001b[32m    374\u001b[39m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m376\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlamb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    377\u001b[39m     mae = \u001b[38;5;28mself\u001b[39m.test(X_test, y_test)\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m np.isnan(mae):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/new/model.py:280\u001b[39m, in \u001b[36mMLPNeuralNetwork.train\u001b[39m\u001b[34m(self, X_train, y_train, alpha, epsilon, lamb, max_epochs, batch_size)\u001b[39m\n\u001b[32m    277\u001b[39m         \u001b[38;5;28mself\u001b[39m.weights[j] -= weight_update\n\u001b[32m    279\u001b[39m \u001b[38;5;66;03m# Evaluate on full training set\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m280\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward_propagation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[38;5;66;03m# Check for NaN in output or weights\u001b[39;00m\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np.isnan(\u001b[38;5;28mself\u001b[39m.output).any():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/new/model.py:172\u001b[39m, in \u001b[36mMLPNeuralNetwork.forward_propagation\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.hidden_layers[i] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.hidden_layers[i].shape[\u001b[32m0\u001b[39m] != batch_size:\n\u001b[32m    171\u001b[39m         neurons_per_layer = \u001b[38;5;28mself\u001b[39m.weights[i].shape[\u001b[32m1\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m         \u001b[38;5;28mself\u001b[39m.hidden_layers[i] = np.zeros((batch_size, neurons_per_layer))\n\u001b[32m    174\u001b[39m \u001b[38;5;66;03m# Forward pass through each layer\u001b[39;00m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.hidden_layers)):\n\u001b[32m    176\u001b[39m     \u001b[38;5;66;03m# Validate matrix dimensions\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "neural_network.grid_search(train_features, train_labels, params, k_fold_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = pipeline.transform(test_df.drop(columns=['Id']))\n",
    "test_id = test_df['Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_price_prediction = neural_network.predict(test_id,test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'submission.csv'\n",
    "housing_price_prediction.to_csv(filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
